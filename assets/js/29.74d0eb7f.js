(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{304:function(e,t,a){"use strict";a.r(t);var s=a(13),n=Object(s.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"blacklab-corpus-query-language-bcql"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#blacklab-corpus-query-language-bcql"}},[e._v("#")]),e._v(" BlackLab Corpus Query Language (BCQL)")]),e._v(" "),t("p",[e._v("BlackLab Corpus Query Language or BCQL is a powerful query language for text corpora.")]),e._v(" "),t("p",[e._v("It is a dialect of the "),t("a",{attrs:{href:"http://cwb.sourceforge.net/files/CQP_Tutorial/",title:"http://cwb.sourceforge.net/files/CQP_Tutorial/",target:"_blank",rel:"noopener noreferrer"}},[e._v("CQP Query Language"),t("OutboundLink")],1),e._v(" introduced by the IMS Corpus WorkBench (CWB). Several other corpus engines support a similar language, such as the "),t("a",{attrs:{href:"https://www.sketchengine.co.uk/documentation/corpus-querying/",title:"https://www.sketchengine.co.uk/documentation/corpus-querying/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Lexicom Sketch Engine"),t("OutboundLink")],1),e._v(". The various dialects are very similar, but differ in some of the more advanced features.")]),e._v(" "),t("p",[e._v("This page will introduce BCQL and show the features that BlackLab supports.")]),e._v(" "),t("p",[e._v("BlackLab started out as purely a token-based corpus engine. The next section shows BCQL's token-based features. After that, we will look at (syntactic) relations querying. Finally, we compare BCQL to CQP, so users familiar with that dialect can avoid common pitfalls.")]),e._v(" "),t("h2",{attrs:{id:"token-based-querying"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#token-based-querying"}},[e._v("#")]),e._v(" Token-based querying")]),e._v(" "),t("h3",{attrs:{id:"matching-a-token"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#matching-a-token"}},[e._v("#")]),e._v(" Matching a token")]),e._v(" "),t("p",[e._v("With BCQL you can specify a pattern of tokens (i.e. words) you're looking for.")]),e._v(" "),t("p",[e._v("A simple such pattern is:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[word='man']\n")])])]),t("p",[e._v("This simply searches for all occurrences of the word "),t("em",[e._v("man")]),e._v(".")]),e._v(" "),t("p",[e._v("Each corpus has a default annotation; usually "),t("em",[e._v("word")]),e._v(". Using this fact, this query can be written even simpler:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'man'\n")])])]),t("p",[e._v("Note that double and single quotes are interchangeable in BCQL (which is not true for all dialects). In this document we will use single quotes.")]),e._v(" "),t("h4",{attrs:{id:"multiple-annotations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multiple-annotations"}},[e._v("#")]),e._v(" Multiple annotations")]),e._v(" "),t("p",[e._v("If your corpus includes the per-word annotations "),t("em",[e._v("lemma")]),e._v(" (i.e. headword) and "),t("em",[e._v("pos")]),e._v(" (part-of-speech, i.e. noun, verb, etc.), you can query those as well.")]),e._v(" "),t("p",[e._v("For example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[lemma='search' & pos='noun']\n")])])]),t("p",[e._v("This query would match "),t("em",[e._v("search")]),e._v(" and "),t("em",[e._v("searches")]),e._v(" where used as a noun. (your data may use different part-of-speech tags, of course)")]),e._v(" "),t("h4",{attrs:{id:"negation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#negation"}},[e._v("#")]),e._v(" Negation")]),e._v(" "),t("p",[e._v('You can use the "does not equal" operator (!=) to search for all words except nouns:')]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[pos != 'noun']\n")])])]),t("h4",{attrs:{id:"regular-expressions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#regular-expressions"}},[e._v("#")]),e._v(" Regular expressions")]),e._v(" "),t("p",[e._v('The strings between quotes can also contain "wildcards", of sorts. To be precise, they are '),t("a",{attrs:{href:"http://en.wikipedia.org/wiki/Regular_expression",target:"_blank",rel:"noopener noreferrer"}},[e._v("regular expressions"),t("OutboundLink")],1),e._v(", which provide a flexible way of matching strings of text. For example, to find "),t("em",[e._v("man")]),e._v(" or "),t("em",[e._v("woman")]),e._v(" (in the default annotation "),t("em",[e._v("word")]),e._v("), use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'(wo)?man'\n")])])]),t("p",[e._v("And to find lemmas starting with "),t("em",[e._v("under")]),e._v(", use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[lemma='under.*']\n")])])]),t("p",[e._v("Explaining regular expression syntax is beyond the scope of this document, but for a complete overview, see "),t("a",{attrs:{href:"http://www.regular-expressions.info/",target:"_blank",rel:"noopener noreferrer"}},[e._v("regular-expressions.info"),t("OutboundLink")],1),e._v(".")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Escaping and literal strings")]),e._v(" "),t("p",[e._v("To find characters with special meaning in a regular expression, such as the period, you need to escape them with a backslash:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[lemma='etc\\.']\n")])])]),t("p",[e._v('Alternatively, you can use a "literal string" by prefixing the string with an '),t("code",[e._v("l")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[lemma=l'etc.']\n")])])])]),e._v(" "),t("h4",{attrs:{id:"matching-any-token"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#matching-any-token"}},[e._v("#")]),e._v(" Matching any token")]),e._v(" "),t("p",[e._v("Sometimes you want to match any token, regardless of its value.")]),e._v(" "),t("p",[e._v("Of course, this is usually only useful in a larger query, as we will explore next. But we'll introduce the syntax here.")]),e._v(" "),t("p",[e._v("To match any token, use the match-all pattern, which is just a pair of empty square brackets:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[]\n")])])]),t("h3",{attrs:{id:"a-sequence-of-tokens"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#a-sequence-of-tokens"}},[e._v("#")]),e._v(" A sequence of tokens")]),e._v(" "),t("p",[e._v("You can search for sequences of words as well (i.e. phrase searches, but with many more possibilities). To search for the phrase "),t("em",[e._v("the tall man")]),e._v(", use this query:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'the' 'tall' 'man'\n")])])]),t("p",[e._v("It might seem a bit clunky to separately quote each word, but this allows us the flexibility to specify exactly what kinds of words we're looking for.")]),e._v(" "),t("p",[e._v("For example, if you want to know all single adjectives used with man (not just "),t("em",[e._v("tall")]),e._v("), use this:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'an?|the' [pos='ADJ'] 'man'\n")])])]),t("p",[e._v("This would also match "),t("em",[e._v("a wise man")]),e._v(", "),t("em",[e._v("an important man")]),e._v(", "),t("em",[e._v("the foolish man")]),e._v(", etc.")]),e._v(" "),t("p",[e._v("If we don't care about the part of speech between the article and "),t("em",[e._v("man")]),e._v(", we can use the match-all pattern we showed before:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'an?|the' [] 'man'\n")])])]),t("p",[e._v("This way we might match something like "),t("em",[e._v("the cable man")]),e._v(" as well as "),t("em",[e._v("a wise man")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"regular-expression-operators-on-tokens"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#regular-expression-operators-on-tokens"}},[e._v("#")]),e._v(" Regular expression operators on tokens")]),e._v(" "),t("p",[e._v("Really powerful token-based queries become possible when you use the regular expression operators on whole tokens as well. If we want to see not just single adjectives applied to "),t("em",[e._v("man")]),e._v(", but multiple as well:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[pos='ADJ']+ 'man'\n")])])]),t("p",[e._v("This query matches "),t("em",[e._v("little green man")]),e._v(", for example. The plus sign after "),t("code",[e._v("[pos='ADJ']")]),e._v(" says that the preceding part should occur one or more times (similarly, "),t("code",[e._v("*")]),e._v(' means "zero or more times", and '),t("code",[e._v("?")]),e._v(' means "zero or once").')]),e._v(" "),t("p",[e._v("If you only want matches with exactly two or three adjectives, you can specify that too:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[pos='ADJ']{2,3} 'man'\n")])])]),t("p",[e._v("Or, for two or more adjectives:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("[pos='ADJ']{2,} 'man'\n")])])]),t("p",[e._v("You can group sequences of tokens with parentheses and apply operators to the whole group as well. To search for a sequence of nouns, each optionally preceded by an article:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("('an?|the'? [pos='NOU'])+\n")])])]),t("p",[e._v("This would, for example, match the well-known palindrome "),t("em",[e._v("a man, a plan, a canal: Panama!")]),e._v(" (provided the punctuation marks were not indexed as separate tokens)")]),e._v(" "),t("h3",{attrs:{id:"case-and-diacritics-sensitivity"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#case-and-diacritics-sensitivity"}},[e._v("#")]),e._v(" Case- and diacritics sensitivity")]),e._v(" "),t("p",[e._v("BlackLab defaults to (case and diacritics) "),t("em",[e._v("insensitive")]),e._v(" search. That is, it ignores differences in upper- and lowercase, as well as diacritical marks (accented characters). So searching for "),t("code",[e._v("'panama'")]),e._v(" will also find "),t("em",[e._v("Panama")]),e._v(".")]),e._v(" "),t("p",[e._v("To match a pattern sensitively, prefix it with "),t("code",[e._v("(?-i)")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'(?-i)Panama'\n")])])]),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("compare to other corpus engines")]),e._v(" "),t("p",[e._v("CWB and Sketch Engine both default to "),t("em",[e._v("sensitive")]),e._v(" search.")])]),e._v(" "),t("h3",{attrs:{id:"matching-xml-elements"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#matching-xml-elements"}},[e._v("#")]),e._v(" Matching XML elements")]),e._v(" "),t("p",[e._v('Your input data may contains "spans": marked regions of text, such as paragraphs, sentences, named entities, etc. If your input data is XML these may be XML elements, but they may also be marked in other ways. Non-XML formats may also define spans.')]),e._v(" "),t("p",[e._v("Finding text in relation to these spans is done using an XML-like syntax, regardless of the exact input data format.")]),e._v(" "),t("h4",{attrs:{id:"finding-spans"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#finding-spans"}},[e._v("#")]),e._v(" Finding spans")]),e._v(" "),t("p",[e._v("If you want to find all the sentence spans in your data:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<s/>\n")])])]),t("p",[e._v('Note that forward slash before the closing bracket. This way of referring to the span means "the whole span". Compare this to '),t("code",[e._v("<s>")]),e._v(', which means "the start of the span", and '),t("code",[e._v("</s>")]),e._v(', which means "the end of the span".')]),e._v(" "),t("p",[e._v("So to find only the starts of sentences, use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<s>\n")])])]),t("p",[e._v("This would find zero-length hits at the position before the first word. Similarly, "),t("code",[e._v("</s>")]),e._v(" finds the ends of sentences. Not very useful, but we can combine these with other queries.")]),e._v(" "),t("h4",{attrs:{id:"words-at-the-start-or-end-of-a-span"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#words-at-the-start-or-end-of-a-span"}},[e._v("#")]),e._v(" Words at the start or end of a span")]),e._v(" "),t("p",[e._v("More useful might be to find the first word of each sentence:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<s> []\n")])])]),t("p",[e._v("or sentences ending in "),t("em",[e._v("that")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'that' </s>\n")])])]),t("p",[e._v("(Note that this assumes the period at the end of the sentence is not indexed as a separate token - if it is, you would use "),t("code",[e._v("'that' '.' </s>")]),e._v(" instead)")]),e._v(" "),t("h4",{attrs:{id:"words-inside-a-span"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#words-inside-a-span"}},[e._v("#")]),e._v(" Words inside a span")]),e._v(" "),t("p",[e._v("You can also search for words occurring inside a specific span. Say you've run named entity recognition on your data, so all names of people are tagged with the "),t("code",[e._v("person")]),e._v(" span. To find the word "),t("em",[e._v("baker")]),e._v(" as part of a person's name, use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'baker' within <person/>\n")])])]),t("p",[e._v("The above query will just match the word "),t("em",[e._v("baker")]),e._v(" as part of a person's name. But you're likely more interested in the entire name that contains the word "),t("em",[e._v("baker")]),e._v(". So, to find those full names, use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<person/> containing 'baker'\n")])])]),t("h4",{attrs:{id:"other-uses-for-within-and-containing"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#other-uses-for-within-and-containing"}},[e._v("#")]),e._v(" Other uses for within and containing")]),e._v(" "),t("p",[e._v("As you might have guessed, you can use "),t("code",[e._v("within")]),e._v(" and "),t("code",[e._v("containing")]),e._v(" with any other query as well. For example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("([pos='ADJ']+ containing 'tall') 'man'\n")])])]),t("p",[e._v("will find adjectives applied to man, where one of those adjectives is "),t("em",[e._v("tall")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"labeling-tokens-capturing-groups"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#labeling-tokens-capturing-groups"}},[e._v("#")]),e._v(" Labeling tokens, capturing groups")]),e._v(" "),t("p",[e._v('Just like in regular expressions, it is possible to "capture" part of the match for your query as a named group. Everything you capture is returned with the hit in a response section called '),t("em",[e._v("match info")]),e._v(".")]),e._v(" "),t("p",[e._v("Example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'an?|the' A:[pos='ADJ'] 'man'\n")])])]),t("p",[e._v("The adjective part of the match will be captured in a group named "),t("em",[e._v("A")]),e._v(".")]),e._v(" "),t("p",[e._v("You can capture multiple words as well:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'an?|the' adjectives:[pos='ADJ']+ 'man'\n")])])]),t("p",[e._v("This will capture the adjectives found for each match in a captured group named "),t("em",[e._v("adjectives")]),e._v(".")]),e._v(" "),t("p",[e._v("The capture name can also just be a number:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'an?|the' 1:[pos='ADJ']+ 'man'\n")])])]),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Compared to other corpus engines")]),e._v(" "),t("p",[e._v("CWB and Sketch Engine offer similar functionality, but instead of capturing part of the match, they label a single token.")]),e._v(" "),t("p",[e._v("BlackLab can capture a span of tokens of any length, capture relations and spans with all their details, and even capture lists of relations, such as all relations in a sentence (relations are described later in this document).")])]),e._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[e._v("Spans are captured automatically")]),e._v(" "),t("p",[e._v("If your query involves spans like "),t("code",[e._v("<s/>")]),e._v(", it will automatically be captured under the span name ("),t("code",[e._v("s")]),e._v(" in this case). You can override the capture name by specifying it in the query, e.g. "),t("code",[e._v("A:<s/>")]),e._v(".")])]),e._v(" "),t("h3",{attrs:{id:"capture-constraints"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#capture-constraints"}},[e._v("#")]),e._v(" Capture constraints")]),e._v(" "),t("p",[e._v('If you tag certain tokens with labels, you can also apply "capture constraints" (also known as "global constraints")\non these tokens. This is a way of relating different tokens to one another, for example requiring that they correspond\nto the same word:')]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("A:[] 'by' B:[] :: A.word = B.word\n")])])]),t("p",[e._v("This would match "),t("em",[e._v("day by day")]),e._v(", "),t("em",[e._v("step by step")]),e._v(", etc.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Multiple-value annotations and constraints")]),e._v(" "),t("p",[e._v("Unfortunately, capture constraints can only access the first value indexed for an annotation. If you need this kind of\nfunctionality in combination with multi-values constraints, you'll have to find a way around this limitation.")]),e._v(" "),t("p",[e._v("Some queries can be rewritten so they don't need a capture constraint. For example,\n"),t("code",[e._v('A:[word="some"] B:[word="queries"] :: A.lemma="some" & B.lemma="query"')]),e._v(" can also be written as\n"),t("code",[e._v('A:[word="some" & lemma="some"] B:[word="queries" & lemma="query"]')]),e._v(", which does work with multiple annotation values.\nBut this is rare.")]),e._v(" "),t("p",[e._v('In other cases, you might be able to add extra annotations or use spans ("inline tags") to get around this limitation.')])]),e._v(" "),t("h4",{attrs:{id:"functions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#functions"}},[e._v("#")]),e._v(" Functions")]),e._v(" "),t("p",[e._v("You can also use a few special functions in capture constraints. For example, ensure that words occur in the right order:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("(<s> containing A:'cat') containing B:'fluffy' :: start(B) < start(A)\n")])])]),t("p",[e._v("Here we find sentences containing both "),t("em",[e._v("cat")]),e._v(" and "),t("em",[e._v("fluffy")]),e._v(" (in some order), but then require that "),t("em",[e._v("fluffy")]),e._v(" occurs before "),t("em",[e._v("cat")]),e._v(".")]),e._v(" "),t("p",[e._v("Of course this particular query would be better expressed as "),t("code",[e._v("<s/> containing 'fluffy' []* 'cat'")]),e._v(". As a general rule,\ncapture constraints can be a bit slower, so only use them when you need to.")]),e._v(" "),t("h4",{attrs:{id:"local-capture-constraints"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#local-capture-constraints"}},[e._v("#")]),e._v(" Local capture constraints")]),e._v(" "),t("p",[e._v("Unlike most other corpus engines, BlackLab allows you to place capture constraints inside a parenthesized expression.\nBe careful that the constraint only refers to labels that are captured inside the parentheses, though!")]),e._v(" "),t("p",[e._v("This is valid and would match "),t("em",[e._v("over and over again")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("(A:[] 'and' B:[] :: A.word = B.word) 'again'\n")])])]),t("p",[e._v("This is NOT valid (may not produce an error, but the results are undefined):")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("A:[] ('and' B:[] :: A.word = B.word) 'again'   # BAD\n")])])]),t("h2",{attrs:{id:"relations-querying"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#relations-querying"}},[e._v("#")]),e._v(" Relations querying")]),e._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[e._v("Supported from v4.0")]),e._v(" "),t("p",[e._v("Indexing and searching relations will be supported from BlackLab 4.0 (and current development snapshots).")])]),e._v(" "),t("p",[e._v("Relations show how (groups of) words are related to one another. One of the most common types of relations is the dependency relation, which shows grammatical dependency between words.")]),e._v(" "),t("p",[e._v("If your corpus contains relations, you can query those as well. One advantage of this style of querying is that it's much easier to find nonadjacent words related to one another, or two related words regardless of what order they occur in.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("How to index relations")]),e._v(" "),t("p",[e._v("Indexing relations is explained "),t("RouterLink",{attrs:{to:"/guide/how-to-configure-indexing.html#indexing-dependency-relations"}},[e._v("here")]),e._v(".")],1)]),e._v(" "),t("p",[e._v('Querying relations is essentially done by building a partial tree of relations constraints. BlackLab will try and find this structure in the corpus. Relations queries can be combined with "regular" token-level queries as well.')]),e._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[e._v("Treebank systems")]),e._v(" "),t("p",[e._v("BlackLab supports limited relations querying, but is not as powerful as a full\ntreebank system, which is primarily designed for this style of search. Links to some treebank systems can be found "),t("a",{attrs:{href:"https://github.com/INL/BlackLab/blob/dev/doc/technical/design/design-relations-queries.md#research-into-treebank-systems",target:"_blank",rel:"noopener noreferrer"}},[e._v("here"),t("OutboundLink")],1),e._v(". For BlackLab's relations querying limitations, see "),t("a",{attrs:{href:"#limitation-descendant-search"}},[e._v("below")]),e._v(".")])]),e._v(" "),t("h3",{attrs:{id:"an-example-dependency-tree"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#an-example-dependency-tree"}},[e._v("#")]),e._v(" An example dependency tree")]),e._v(" "),t("p",[e._v("Let's use an example to illustrate the various querying options. Here's a simple dependency tree for the phrase "),t("em",[e._v("I have a fluffy cat")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("      |\n     have\n    /    \\\n (subj)   (obj)\n /          \\\nI            cat\n           /   |\n        (det)(amod)\n        /      |\n       a     fluffy \n")])])]),t("h3",{attrs:{id:"finding-specific-relation-types"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#finding-specific-relation-types"}},[e._v("#")]),e._v(" Finding specific relation types")]),e._v(" "),t("p",[e._v("We might want to find object relations in our data. We can do this as follows:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -obj-> _\n")])])]),t("p",[e._v("This will find "),t("em",[e._v("have a fluffy cat")]),e._v(" (the span of text covering the two ends of the relation), with a match info group named for the relation type ("),t("em",[e._v("obj")]),e._v(") containing the relation details between "),t("em",[e._v("have")]),e._v(" and "),t("em",[e._v("cat")]),e._v(".")]),e._v(" "),t("p",[e._v("The two "),t("code",[e._v("_")]),e._v(" marks in the query simply means we only care about the relation type, not the source or target of the relation. If we specifically want to find instances where "),t("em",[e._v("cat")]),e._v(" is the object of the sentence, we can use this instead:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -obj-> 'cat'\n")])])]),t("p",[e._v("So you can see that the token-based queries described previously are still useful here.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Can I use [] instead of _ ?")]),e._v(" "),t("p",[e._v("As explained above, "),t("code",[e._v("_")]),e._v(' in a relation expression means "any source or target". You might be tempted to use '),t("code",[e._v("[]")]),e._v(" instead, especially if you know your relations always have a single-token source and target. This works just fine, but it's a bit slower (it has to double-check that source and target are actually of length 1), so we recommend sticking with "),t("code",[e._v("_")]),e._v(".")]),e._v(" "),t("p",[e._v("(the actual equivalent of "),t("code",[e._v("_")]),e._v(" here is "),t("code",[e._v("[]*")]),e._v(" (zero or more tokens with no restrictions), but that makes for less readable queries)")])]),e._v(" "),t("h3",{attrs:{id:"a-note-on-terminology"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#a-note-on-terminology"}},[e._v("#")]),e._v(" A note on terminology")]),e._v(" "),t("p",[e._v("For dependency relations, linguists call the left side the "),t("em",[e._v("head")]),e._v(" of the relation and the right side the "),t("em",[e._v("dependent")]),e._v(". However, because dependency relations aren't the only class of relation, and because the term "),t("em",[e._v("head")]),e._v(" can be a bit confusing (there's also the \"head of an arrow\", but that's the other end!), we will use "),t("em",[e._v("source")]),e._v(" and "),t("em",[e._v("target")]),e._v(".")]),e._v(" "),t("p",[e._v("When talking about tree structures, we will also use "),t("em",[e._v("parent")]),e._v(" and "),t("em",[e._v("child")]),e._v(".")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Context")]),e._v(" "),t("th",[e._v("Terms")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("Dependency relations")]),e._v(" "),t("td",[t("code",[e._v("head --\x3e dependent")])])]),e._v(" "),t("tr",[t("td",[e._v("Relations in BlackLab")]),e._v(" "),t("td",[t("code",[e._v("source --\x3e target")])])]),e._v(" "),t("tr",[t("td",[e._v("Searching tree structures")]),e._v(" "),t("td",[t("code",[e._v("parent --\x3e child")])])])])]),e._v(" "),t("h3",{attrs:{id:"finding-relation-types-using-regular-expressions"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#finding-relation-types-using-regular-expressions"}},[e._v("#")]),e._v(" Finding relation types using regular expressions")]),e._v(" "),t("p",[e._v("We can specify the relation type as a regular expression as well. To find both subject and object relations, we could use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -subj|obj-> _\n")])])]),t("p",[e._v("or:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -.*bj-> _\n")])])]),t("p",[e._v("If you find it clearer, you can use parentheses around the regular expression:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -(subj|obj)-> _\n")])])]),t("p",[e._v("With our example tree, the above queries will find all subject relations and all object relations. Each hit will have one relation in the match info. To find multiple relations per hit, read on.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Relation classes")]),e._v(" "),t("p",[e._v("When indexing relations in BlackLab, you assign them a "),t("em",[e._v("class")]),e._v(", a short string indicating what family of relations it belongs to. For example, you could assign the class string "),t("code",[e._v("dep")]),e._v(" to dependency relations. An "),t("code",[e._v("obj")]),e._v(" relation would become "),t("code",[e._v("dep::obj")]),e._v(".")]),e._v(" "),t("p",[e._v("To simplify things, "),t("code",[e._v("dep")]),e._v(" is the default relation class in BlackLab. If you index relations without a class, they will automatically get the "),t("code",[e._v("dep")]),e._v(" class. Similarly, when searching, if you don't specify a class, "),t("code",[e._v("dep::")]),e._v(" will be prepended to the relation type. So if you're not indexing different classes of relations, you can just ignore the classes.")])]),e._v(" "),t("h3",{attrs:{id:"root-relations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#root-relations"}},[e._v("#")]),e._v(" Root relations")]),e._v(" "),t("p",[e._v("A dependency tree has a single root relation. A root relation is special relation that only has a target and no source. Its relation type is usually just called "),t("em",[e._v("root")]),e._v(". In our example, the root points to the word "),t("em",[e._v("have")]),e._v(".")]),e._v(" "),t("p",[e._v("You can find root relations with a special unary operator:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("^--\x3e _\n")])])]),t("p",[e._v("This will find all root relations. The details for the root relation will be returned in the match info.")]),e._v(" "),t("p",[e._v("Of course you can place constraints on the target of the root relation as well:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("^--\x3e 'have'\n")])])]),t("p",[e._v("This will only find root relations pointing to the word "),t("em",[e._v("have")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"finding-two-relations-with-the-same-source"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#finding-two-relations-with-the-same-source"}},[e._v("#")]),e._v(" Finding two relations with the same source")]),e._v(" "),t("p",[e._v("What if we want to find the subject and object relations of a sentence, both linked to the same source (the verb in the sentence)? We can do that using a semicolon to separate the two "),t("em",[e._v("target constraints")]),e._v(" (or "),t("em",[e._v("child constraints")]),e._v("):")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -subj-> _ ;\n  -obj-> _\n")])])]),t("p",[e._v("As you can see, the source or parent is specified only once at the beginning. Then you may specify one or more target constraints (a relation type plus target, e.g. "),t("code",[e._v("-subj-> _")]),e._v("), separated by semicolons.")]),e._v(" "),t("p",[e._v("The above query will find hits covering the words involved in both relations, with details for the two relations in the match info of each hit. In our example, it would find the entire sentence "),t("em",[e._v("I have a fluffy cat")]),e._v(".")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Target constraint uniqueness")]),e._v(" "),t("p",[e._v("Note that when matching multiple relations with the same source this way, BlackLab will enforce that they are unique. That is, two target constraints will only match two different relations.")])]),e._v(" "),t("h3",{attrs:{id:"negative-child-constraints"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#negative-child-constraints"}},[e._v("#")]),e._v(" Negative child constraints")]),e._v(" "),t("p",[e._v("You may want to have negative constraints, such as making sure that "),t("em",[e._v("dog")]),e._v(" is not the object of the sentence. This can be done by prefixing the relation operator with "),t("code",[e._v("!")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_  -subj-> _ ;\n  !-obj-> 'dog'\n")])])]),t("p",[e._v("Note that this is different from :")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_  -subj-> _ ;\n   -obj-> [word != 'dog']\n")])])]),t("p",[e._v("The second query requires an object relation where the target is a word other than "),t("em",[e._v("dog")]),e._v("; that is, the object relation must exist. By contrast, in the first case, we only require that there exists no object relation with the target "),t("em",[e._v("dog")]),e._v(", so this might match sentences without an object as well as sentences with an object that is not "),t("em",[e._v("dog")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"searching-over-multiple-levels-in-the-tree"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#searching-over-multiple-levels-in-the-tree"}},[e._v("#")]),e._v(" Searching over multiple levels in the tree")]),e._v(" "),t("p",[e._v("What if we want to query over multiple levels of the tree? For example, we want to find sentences where the target of the "),t("code",[e._v("subj")]),e._v(" relation is the source of an "),t("code",[e._v("amod")]),e._v(" relation pointing to "),t("em",[e._v("fluffy")]),e._v(", such as in our example tree.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -subj-> _ -amod-> 'fluffy'\n")])])]),t("p",[e._v("We can combine the techniques as well, for example if we also want to find the object of the sentence like before:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("_ -subj-> (_ -amod-> _) ;\n  -obj-> _\n")])])]),t("p",[e._v("As you can see, the value of the expression "),t("code",[e._v("(_ -amod-> _)")]),e._v(" is actually the "),t("em",[e._v("source")]),e._v(" of the "),t("code",[e._v("amod")]),e._v(" relation, so we can easily use it as the target of the "),t("code",[e._v("subj")]),e._v(" relation.")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("-..->")]),e._v(" operator is right-associative (as you can see from the first example), but we do need parentheses here, or the parent of the "),t("code",[e._v("-obj->")]),e._v(" relation would be ambiguous.")]),e._v(" "),t("h3",{attrs:{id:"limitation-descendant-search"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#limitation-descendant-search"}},[e._v("#")]),e._v(" Limitation: descendant search")]),e._v(" "),t("p",[e._v("One current limitation compared to dedicated treebank systems is the lack\nof support for finding descendants that are not direct children.")]),e._v(" "),t("p",[e._v("For example, if we want to look for sentences with the verb "),t("em",[e._v("have")]),e._v(" and the word "),t("em",[e._v("fluffy")]),e._v(" somewhere as an adjectival modifier in that sentence, we can't query something like this:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("^--\x3e 'have' --\x3e> -amod-> 'fluffy'   # DOES NOT WORK\n")])])]),t("p",[e._v("Instead, we have to know how many nodes are between "),t("em",[e._v("have")]),e._v(" and "),t("em",[e._v("fluffy")]),e._v(", e.g. this does work:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("^--\x3e 'have' --\x3e _ -amod-> 'fluffy'\n")])])]),t("p",[e._v("Supporting arbitrary descendant search with decent performance is a challenge that we may try to tackle in the future.")]),e._v(" "),t("p",[e._v("For now, you might be able to work around this limitation using a hybrid between token-based and relations querying, e.g.:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("(<s/> containing (^--\x3e 'have')) containing (_ -amod-> 'fluffy')\n")])])]),t("h3",{attrs:{id:"advanced-relations-querying-features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#advanced-relations-querying-features"}},[e._v("#")]),e._v(" Advanced relations querying features")]),e._v(" "),t("p",[e._v("Most users won't need this, but they might come in handy in some cases.")]),e._v(" "),t("h4",{attrs:{id:"controlling-the-resulting-span"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#controlling-the-resulting-span"}},[e._v("#")]),e._v(" Controlling the resulting span")]),e._v(" "),t("p",[e._v("As shown in the previous section, relation expressions return the source of the matching relation by default. But what if you want a different part of the relation?")]),e._v(" "),t("p",[e._v("For example, if we want to find targets of the "),t("em",[e._v("amod")]),e._v(" relation, we can do this:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("rspan(_ -amod-> _, 'target')\n")])])]),t("p",[e._v("If we want the entire span covering both the source and the target (and anything in between):")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("rspan(_ -amod-> _, 'full')\n")])])]),t("p",[e._v("Note that "),t("em",[e._v("full")]),e._v(" is the default value for the second parameter, so this will work too:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("rspan(_ -amod-> _)\n")])])]),t("p",[t("code",[e._v("rspan")]),e._v(" supports another option: "),t("em",[e._v("all")]),e._v(" will return a span covering all of the relations matched by your query.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("rspan(_ -subj-> (_ -amod-> _) ; -obj-> _, 'all')\n")])])]),t("p",[e._v("Because this is pretty useful when searching relations, there's an easy way to apply this "),t("code",[e._v("rspan")]),e._v(" operation: just add a parameter "),t("code",[e._v("adjusthits=yes")]),e._v(" to your BlackLab Server URL. Note that if your query already starts with a call to "),t("code",[e._v("rspan")]),e._v(", "),t("code",[e._v("adjusthits=yes")]),e._v(" won't do anything.")]),e._v(" "),t("h4",{attrs:{id:"capturing-all-relations-in-a-sentence"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#capturing-all-relations-in-a-sentence"}},[e._v("#")]),e._v(" Capturing all relations in a sentence")]),e._v(" "),t("p",[e._v("If you want to capture all relations in the sentence containing your match, use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'elephant' within rcapture(<s/>)\n")])])]),t("p",[e._v("What actually happens here is that all relations in the matched clause are returned in the match info.")]),e._v(" "),t("p",[e._v("You can pass a second parameter with the match info name for the list of captured relations (defaults to "),t("em",[e._v("captured_rels")]),e._v("):")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'elephant' within rcapture(<s/>, 'relations')\n")])])]),t("p",[e._v("If you only want to capture certain relations, you specify a third parameter that is a regular expression filter on the relation type. For example, to only capture relations in the "),t("code",[e._v("fam")]),e._v(" class, use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'elephant' within rcapture(<s/>, 'relations', 'fam::.*')\n")])])]),t("h4",{attrs:{id:"cross-field-relations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#cross-field-relations"}},[e._v("#")]),e._v(" Cross-field relations")]),e._v(" "),t("p",[e._v("It is possible to have a corpus with multiple annotated fields, with relations that point from a position or span in one field to another. Annotated fields should be named e.g. "),t("code",[e._v("contents__original")]),e._v(" and "),t("code",[e._v("contents__corrected")]),e._v(" for this to work, and a relation from the first to the second field could be found like this:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'mistpyed' --\x3ecorrected 'mistyped'\n")])])]),t("p",[e._v("As you can see, the target version is appended to the relation operator. The source version is determined by the main annotated field searched (the "),t("code",[e._v("field")]),e._v(" parameter for BlackLab Server; will default to the main annotated field, which is the first one you defined in your indexing configuration).")]),e._v(" "),t("p",[e._v("Cross-field relations are used to enable parallel corpora, which we'll discuss next.")]),e._v(" "),t("h2",{attrs:{id:"parallel-corpus-querying"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#parallel-corpus-querying"}},[e._v("#")]),e._v(" Parallel corpus querying")]),e._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[e._v("Supported from v4.0")]),e._v(" "),t("p",[e._v("Indexing and searching parallel corpoora will be supported from BlackLab 4.0 (and current development snapshots).")])]),e._v(" "),t("p",[e._v("A parallel corpus is a corpus that contains multiple versions of the corpus content, usually from different languages and/or time periods, and record the alignment between the versions at different levels (e.g. paragraph, sentence, word).")]),e._v(" "),t("p",[e._v("For example, you could have a parallel corpus of EU Parliament discussions in the various European languages, or a parallel corpus of different translations of a classic work such as Homer's Odyssey.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("How to index a parallel corpus")]),e._v(" "),t("p",[e._v("Indexing parallel corpora is explained "),t("RouterLink",{attrs:{to:"/guide/how-to-configure-indexing.html#indexing-parallel-corpora"}},[e._v("here")]),e._v(".")],1)]),e._v(" "),t("p",[e._v("BlackLab's parallel corpus functionality uses cross-field relations to find alignments between the content versions available in your corpus.")]),e._v(" "),t("p",[e._v("The alignments operator "),t("code",[e._v("==>")]),e._v(' is specifically to find alignments between versions in your corpus. It essentially means "capture all relations between (part of) the left and right span". It will capture a list of relations in the response.')]),e._v(" "),t("h3",{attrs:{id:"basic-parallel-querying"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#basic-parallel-querying"}},[e._v("#")]),e._v(" Basic parallel querying")]),e._v(" "),t("p",[e._v("For example, if your corpus contains fields "),t("code",[e._v("contents__en")]),e._v(" (English version) and "),t("code",[e._v("contents__nl")]),e._v(" (Dutch version), and English is the default field (the first one defined in your indexing config), you can find the Dutch translation of an English word using:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'cat' ==>nl _\n")])])]),t("p",[e._v("The hit for this query will be "),t("code",[e._v("cat")]),e._v(" in the English field, and the match info will contain a group named "),t("code",[e._v("rels")]),e._v(" with all alignment relations found (just the one in this case, between the word "),t("code",[e._v("cat")]),e._v(" and its Dutch equivalent). The hit response structure will also contain an "),t("code",[e._v("otherFields")]),e._v(" section containing the corresponding Dutch content fragment. The location of the Dutch word aligned with the English word "),t("code",[e._v("cat")]),e._v(" can be found from the relation in the "),t("code",[e._v("rel")]),e._v(" capture, which includes "),t("code",[e._v("targetField")]),e._v(", "),t("code",[e._v("targetStart")]),e._v(" and "),t("code",[e._v("targetEnd")]),e._v(".")]),e._v(" "),t("p",[e._v("Assuming your data has both sentence and word alignments, and you want to find all alignments for a sentence containing "),t("code",[e._v("cat")]),e._v(", you could use:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<s/> containing 'cat' ==>nl _\n")])])]),t("p",[e._v("This should find aligning English and Dutch sentences, including any word alignments between words in those sentences. You can also filter by alignment type, as we'll show later.")]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Required versus optional alignment")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("==>")]),e._v(" operator will "),t("em",[e._v("require")]),e._v(" that an alignment exists. If you wish to see all hits on the left side of the "),t("code",[e._v("==>nl")]),e._v(" regardless of whether any aligments to the right side can be found, use "),t("code",[e._v("==>nl?")]),e._v(".")]),e._v(" "),t("p",[e._v("For example, if you're searching for translations of "),t("code",[e._v("cat")]),e._v(" to Dutch, with "),t("code",[e._v("==>nl")]),e._v(" you will "),t("em",[e._v("only")]),e._v(" see instances where "),t("code",[e._v("cat")]),e._v(" is aligned to a Dutch word; on the other hand, with "),t("code",[e._v("==>nl?")]),e._v(" you will see both English "),t("code",[e._v("cat")]),e._v(" hits where the translation to Dutch was found, and "),t("code",[e._v("cat")]),e._v(" hits where it wasn't.")])]),e._v(" "),t("h3",{attrs:{id:"switching-the-main-search-field"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#switching-the-main-search-field"}},[e._v("#")]),e._v(" Switching the main search field")]),e._v(" "),t("p",[e._v("If you want to search the Dutch version instead, and find alignments with the English version, you would use this query:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'kat' ==>en _\n")])])]),t("p",[e._v("But of course, the main search field shouldn't be "),t("code",[e._v("contents__en")]),e._v(" in this case; we want to switch it to "),t("code",[e._v("contents__nl")]),e._v(". You can specify a main search field other than the default with the BLS parameter "),t("code",[e._v("field")]),e._v(". In this case, if you specify "),t("code",[e._v("field=nl")]),e._v(". BlackLab will automatically recognize that you're specifying a version of the main annotated field and use the correct 'real' field, probably "),t("code",[e._v("contents__nl")]),e._v(" in this case.")]),e._v(" "),t("h3",{attrs:{id:"filtering-the-target-span"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#filtering-the-target-span"}},[e._v("#")]),e._v(" Filtering the target span")]),e._v(" "),t("p",[e._v("In the previous example, we used "),t("code",[e._v("_")]),e._v(' as the target span. This is the default, and means "the best matching span".')]),e._v(" "),t("p",[e._v("But you can also specify a different target span. For example, to find where "),t("em",[e._v("fluffy")]),e._v(" was translated to "),t("em",[e._v("pluizig")]),e._v(":")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'fluffy' ==>nl 'pluizig'\n")])])]),t("p",[e._v("This will execute the left and right queries on their respective fields and match the hits by their alignment relations.")]),e._v(" "),t("h3",{attrs:{id:"multiple-alignment-queries"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multiple-alignment-queries"}},[e._v("#")]),e._v(" Multiple alignment queries")]),e._v(" "),t("p",[e._v("You can also use multiple alignment operators in a single query to match to more than one other version:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'fluffy' ==>nl 'pluizig' ;\n         ==>de 'flauschig'\n")])])]),t("h3",{attrs:{id:"only-matching-some-alignment-relations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#only-matching-some-alignment-relations"}},[e._v("#")]),e._v(" Only matching some (alignment) relations")]),e._v(" "),t("p",[e._v("Just like with other relations queries, you can filter by type:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("'fluffy' =word=>nl 'pluizig'\n")])])]),t("p",[e._v("This will only find relations of type "),t("code",[e._v("word")]),e._v(". The type filter will automatically determine the capture name as well, so any relation(s) found will be captured as "),t("code",[e._v("word")]),e._v(" in this case instead of "),t("code",[e._v("rels")]),e._v(" (unless an explicit name is assigned, see below).")]),e._v(" "),t("h3",{attrs:{id:"renaming-the-relations-capture"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#renaming-the-relations-capture"}},[e._v("#")]),e._v(" Renaming the relations capture")]),e._v(" "),t("p",[e._v("You can use a override the default name "),t("code",[e._v("rels")]),e._v(" for the alignment operator's captures:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v("<s/> alignments:==>nl _\n")])])]),t("p",[e._v("Now the alignment relations will be captured in a group named "),t("code",[e._v("alignments")]),e._v(".")]),e._v(" "),t("h3",{attrs:{id:"capturing-in-target-fields"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#capturing-in-target-fields"}},[e._v("#")]),e._v(" Capturing in target fields")]),e._v(" "),t("p",[e._v("You can capture parts of the target query like normal, e.g.:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[e._v('"and" w1:[] ==>nl "en" w2:[]\n')])])]),t("p",[e._v("There will be one match info named "),t("code",[e._v("w1")]),e._v(" for the primary field searched (English in this case), and one named "),t("code",[e._v("w2")]),e._v(" for the target field (Dutch).")]),e._v(" "),t("h2",{attrs:{id:"advanced-subjects"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#advanced-subjects"}},[e._v("#")]),e._v(" Advanced subjects")]),e._v(" "),t("h3",{attrs:{id:"operator-precedence"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#operator-precedence"}},[e._v("#")]),e._v(" Operator precedence")]),e._v(" "),t("p",[e._v('This is the precedence of the different CQL operators in BlackLab, from highest to lowest. The highest precedence operators "bind most tightly". See the examples below.')]),e._v(" "),t("p",[e._v("Inside token brackets "),t("code",[e._v("[ ]")]),e._v(":")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Operator")]),e._v(" "),t("th",[e._v("Description")]),e._v(" "),t("th",[e._v("Associativity")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("!")])]),e._v(" "),t("td",[e._v("logical not")]),e._v(" "),t("td",[e._v("right-to-left")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("=")]),e._v(" "),t("code",[e._v("!=")])]),e._v(" "),t("td",[e._v("(not) equals")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("&")]),e._v(" "),t("code",[e._v("\\|")])]),e._v(" "),t("td",[e._v("logical and/or")]),e._v(" "),t("td",[e._v("left-to-right")])])])]),e._v(" "),t("p",[e._v("At the sequence level (i.e. outside token brackets):")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Operator")]),e._v(" "),t("th",[e._v("Description")]),e._v(" "),t("th",[e._v("Associativity")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("!")])]),e._v(" "),t("td",[e._v("logical not")]),e._v(" "),t("td",[e._v("right-to-left")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("[ ]")])]),e._v(" "),t("td",[e._v("token brackets")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("( )")])]),e._v(" "),t("td",[e._v("function call")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("*")]),e._v(" "),t("code",[e._v("+")]),e._v(" "),t("code",[e._v("?")]),t("br"),t("code",[e._v("{n}")]),e._v(" "),t("code",[e._v("{n,m}")])]),e._v(" "),t("td",[e._v("repetition")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v(":")])]),e._v(" "),t("td",[e._v("capture")]),e._v(" "),t("td",[e._v("right-to-left")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("< />")]),e._v(" "),t("code",[e._v("< >")]),e._v(" "),t("code",[e._v("</ >")])]),e._v(" "),t("td",[e._v("span (start/end)")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("[] []")])]),e._v(" "),t("td",[e._v("sequence"),t("br"),e._v("(implied operator)")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("\\|")]),e._v(" "),t("code",[e._v("&")])]),e._v(" "),t("td",[e._v("union/intersection")]),e._v(" "),t("td",[e._v("left-to-right")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("--\x3e [ ; --\x3e ]")]),t("br"),t("code",[e._v("^--\x3e")]),t("br"),t("code",[e._v("==> [ ; ==> ]")])]),e._v(" "),t("td",[e._v("child relations"),t("br"),e._v("root relation"),t("br"),e._v("alignment")]),e._v(" "),t("td",[e._v("right-to-left")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("within")]),e._v(" "),t("code",[e._v("containing")])]),e._v(" "),t("td",[e._v("position filter")]),e._v(" "),t("td",[e._v("right-to-left")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("::")])]),e._v(" "),t("td",[e._v("capture constraint")]),e._v(" "),t("td",[e._v("left-to-right")])])])]),e._v(" "),t("p",[e._v("NOTES:")]),e._v(" "),t("ul",[t("li",[e._v("you can always use grouping parens "),t("code",[e._v("( )")]),e._v(" (at either token or sequence level) to override this precedence.")]),e._v(" "),t("li",[e._v("notice that "),t("code",[e._v("|")]),e._v(" and "),t("code",[e._v("&")]),e._v(" have the "),t("em",[e._v("same")]),e._v(" precedence; don't rely on "),t("code",[e._v("&")]),e._v(" binding more tightly than "),t("code",[e._v("|")]),e._v(" or vice versa, which you might be used to from other languages.")])]),e._v(" "),t("p",[e._v("A few examples:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Query")]),e._v(" "),t("th",[e._v("Interpreted as")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("[word = 'can' & pos != 'verb']")])]),e._v(" "),t("td",[t("code",[e._v("[ (word = 'can') & (pos != 'verb') ]")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("[pos = 'verb' \\| pos = 'noun' & word = 'can']")])]),e._v(" "),t("td",[t("code",[e._v("[ (pos = 'verb' \\| pos = 'noun') & word = 'can']")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("A:'very'+")])]),e._v(" "),t("td",[t("code",[e._v("A:('very'+)")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("A:_ --\x3e B:_")])]),e._v(" "),t("td",[t("code",[e._v("(A:_) --\x3e (B:_)")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("_ -obj-> _ -amod-> _")])]),e._v(" "),t("td",[t("code",[e._v("_ -obj-> (_ -amod-> _)")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("!'d.*' & '.e.*'")])]),e._v(" "),t("td",[t("code",[e._v("(!'d.*') & '.e.*'")]),e._v(", meaning "),t("br"),t("code",[e._v("[word != 'd.*' & word = '.e.*']")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("'cow' within <pasture/> containing 'grass'")])]),e._v(" "),t("td",[t("code",[e._v("'cow' within (<pasture/> containing 'grass')")])])])])]),e._v(" "),t("h3",{attrs:{id:"supported-features-differences-from-cwb"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#supported-features-differences-from-cwb"}},[e._v("#")]),e._v(" Supported features, differences from CWB")]),e._v(" "),t("p",[e._v("For those who already know CQL, here's a quick overview of the extent of BlackLab's support for this query language. If you a feature we don't support yet is important to you, please let us know. If it's quick to add, we may be able to help you out.")]),e._v(" "),t("h3",{attrs:{id:"supported-features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#supported-features"}},[e._v("#")]),e._v(" Supported features")]),e._v(" "),t("p",[e._v("BlackLab currently supports (arguably) most of the important features of Corpus Query Language:")]),e._v(" "),t("ul",[t("li",[e._v("Matching on token annotations, using regular expressions and "),t("code",[e._v("=")]),e._v(", "),t("code",[e._v("!=")]),e._v(", "),t("code",[e._v("!")]),e._v(". Example: "),t("code",[e._v("[word='bank']")]),e._v(" (or just "),t("code",[e._v("'bank'")]),e._v(")")]),e._v(" "),t("li",[e._v("Case/accent sensitive matching. Note that, unlike in CWB, case-INsensitive matching is currently the default. To explicitly match case-/accent-insensitively, use "),t("code",[e._v("'(?i)...'")]),e._v(". Example: "),t("code",[e._v("'(?-i)Mr\\.' '(?-i)Banks'")])]),e._v(" "),t("li",[e._v("Combining criteria using "),t("code",[e._v("&")]),e._v(", "),t("code",[e._v("|")]),e._v(" and "),t("code",[e._v("!")]),e._v(". Parentheses can also be used for grouping. Example: "),t("code",[e._v("[lemma='bank' & pos='V']")])]),e._v(" "),t("li",[e._v("Matchall pattern "),t("code",[e._v("[]")]),e._v(" matches any token. Example: "),t("code",[e._v("'a' [] 'day'")])]),e._v(" "),t("li",[e._v("Regular expression operators "),t("code",[e._v("+")]),e._v(", "),t("code",[e._v("*")]),e._v(", "),t("code",[e._v("?")]),e._v(", "),t("code",[e._v("{n}")]),e._v(", "),t("code",[e._v("{n,m}")]),e._v(" at the token level. Example: "),t("code",[e._v("[pos='ADJ']+")])]),e._v(" "),t("li",[e._v("Sequences of token constraints. Example: "),t("code",[e._v("[pos='ADJ'] 'cow'")])]),e._v(" "),t("li",[e._v("Operators "),t("code",[e._v("|")]),e._v(", "),t("code",[e._v("&")]),e._v(" and parentheses can be used to build complex sequence queries. Example: "),t("code",[e._v("'happy' 'dog' | 'sad' cat'")])]),e._v(" "),t("li",[e._v("Querying with tag positions using e.g. "),t("code",[e._v("<s>")]),e._v(" (start of sentence), "),t("code",[e._v("</s>")]),e._v(" (end of sentence), "),t("code",[e._v("<s/>")]),e._v(" (whole sentence) or "),t("code",[e._v("<s> ... </s>")]),e._v(" (equivalent to "),t("code",[e._v("<s/> containing ...")]),e._v("). Example: "),t("code",[e._v("<s> 'The'")]),e._v(". XML attribute values may be used as well, e.g. "),t("code",[e._v("<ne type='PERS'/>")]),e._v(' ("named entities that are persons").')]),e._v(" "),t("li",[e._v("Using "),t("code",[e._v("within")]),e._v(" and "),t("code",[e._v("containing")]),e._v(" operators to find hits inside another set of hits. Example: "),t("code",[e._v("'you' 'are' within <s/>")])]),e._v(" "),t("li",[e._v("Using an anchor to capture a token position. Example: "),t("code",[e._v("'big' A:[]")]),e._v(". Captured matches can be used in capture\nconstraints (see next item) or processed separately later (using the Java interface; capture information is not yet returned by BlackLab Server). Note that BlackLab can actually capture entire groups of tokens as well, similarly to regular expression engines.")]),e._v(" "),t("li",[e._v("Capture constraints, such as requiring two captures to contain the same word. Example: "),t("code",[e._v("'big' A:[] 'or' 'small' B:[] :: A.word = B.word")])])]),e._v(" "),t("p",[e._v("See below for features not in this list that may be added soon, and let us know if you want a particular feature to be added.")]),e._v(" "),t("h3",{attrs:{id:"differences-from-cwb"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#differences-from-cwb"}},[e._v("#")]),e._v(" Differences from CWB")]),e._v(" "),t("p",[e._v("BlackLab's CQL syntax and behaviour differs in a few ways from CWBs, although they are mostly lesser-used features.")]),e._v(" "),t("p",[e._v("For now, here's what you should know:")]),e._v(" "),t("ul",[t("li",[e._v("Case-insensitive search is the default in BlackLab, while CWB and Sketch Engine use case-sensitive search as the default. If you want to match a term case-sensitively, use "),t("code",[e._v("'(?-i)..'")]),e._v(" or "),t("code",[e._v("'(?c)..'")]),e._v(".")]),e._v(" "),t("li",[e._v("If you want to match a string literally, not as a regular expression, use backslash escaping ("),t("code",[e._v("'e\\.g\\.'")]),e._v(") or a literal string ("),t("code",[e._v("l'e.g.'")]),e._v(")")]),e._v(" "),t("li",[e._v("BlackLab supports result set manipulation such as: sorting (including on specific context words), grouping/frequency distribution, subsets, sampling, setting context size, etc. However, these are supported through the REST and Java APIs, not through a command interface like in CWB. See "),t("RouterLink",{attrs:{to:"/server/overview.html"}},[e._v("BlackLab Server overview")]),e._v(").")],1),e._v(" "),t("li",[e._v("Querying XML elements and attributes looks natural in BlackLab: "),t("code",[e._v("<s/>")]),e._v(' means "sentences", '),t("code",[e._v("<s>")]),e._v(' means "starts of sentences", '),t("code",[e._v("<s type='A'>")]),e._v(' means "sentence tags with a type attribute with value A". This natural syntax differs from CWBs in some places, however, particularly when matching XML attributes.')]),e._v(" "),t("li",[e._v("In capture constraints (expressions occurring after "),t("code",[e._v("::")]),e._v("), only literal matching (no regex matching) is currently supported.")]),e._v(" "),t("li",[e._v("To return whole sentences as the context of hits, pass "),t("code",[e._v("context=s")]),e._v(" to BLS.")]),e._v(" "),t("li",[e._v("The implication operator "),t("code",[e._v("->")]),e._v(" is currently only supported in capture constraints (expressions after the "),t("code",[e._v("::")]),e._v(" operator), not in a regular token constraints.")]),e._v(" "),t("li",[e._v("We don't support the "),t("code",[e._v("@")]),e._v(" anchor and corresponding "),t("code",[e._v("target")]),e._v(" label; use a named anchor instead.")]),e._v(" "),t("li",[e._v("backreferences to anchors only work in capture constraints, so this doesn't work: "),t("code",[e._v("A:[] [] [word = A.word]")]),e._v(". Instead, use something like: "),t("code",[e._v("A:[] [] B:[] :: A.word = B.word")]),e._v(".")]),e._v(" "),t("li",[e._v("Instead of CWBs "),t("code",[e._v("intersection")]),e._v(", "),t("code",[e._v("union")]),e._v(" and "),t("code",[e._v("difference")]),e._v(" operators, BlackLab supports the "),t("code",[e._v("&")]),e._v(", "),t("code",[e._v("|")]),e._v(" and "),t("code",[e._v("!")]),e._v(" operators at the top-level of the query, e.g. "),t("code",[e._v("('double' [] & [] 'trouble')")]),e._v(" to match the intersection of these queries, i.e. 'double trouble' and "),t("code",[e._v("('happy' 'dog' | 'sad 'cat')")]),e._v(" to match the union of 'happy dog' and 'sad cat'. Difference can be achieved by combining "),t("code",[e._v("!")]),e._v(" and "),t("code",[e._v("&")]),e._v(", e.g. "),t("code",[e._v("('happy' [] & !([] 'dog'))")]),e._v(" to match 'happy' followed by anything except 'dog' (although this is better expressed as "),t("code",[e._v("'happy' [word != 'dog']")]),e._v(").")])]),e._v(" "),t("h3",{attrs:{id:"currently-unsupported-features"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#currently-unsupported-features"}},[e._v("#")]),e._v(" (Currently) unsupported features")]),e._v(" "),t("p",[e._v("Some features that are not (yet) supported:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("lbound")]),e._v(", "),t("code",[e._v("rbound")]),e._v(" functions to get the edge of a region. You can use "),t("code",[e._v("<s>")]),e._v(" to get all starts-of-sentences or "),t("code",[e._v("</s>")]),e._v(" to get all ends-of-sentences, however.")]),e._v(" "),t("li",[t("code",[e._v("distance")]),e._v(", "),t("code",[e._v("distabs")]),e._v(" functions and "),t("code",[e._v("match")]),e._v(", "),t("code",[e._v("matchend")]),e._v(" anchor points (sometimes used in capture constraints).")]),e._v(" "),t("li",[e._v("using an XML element name to mean 'token is contained within', like "),t("code",[e._v("[(pos = 'N') & !np]")]),e._v(' meaning "noun NOT inside in an '),t("code",[e._v("<np/>")]),e._v(' tag".')]),e._v(" "),t("li",[e._v("a number of less well-known features.")])]),e._v(" "),t("p",[e._v("If people ask about missing features, we're happy to work with them to see if it could be added.")])])}),[],!1,null,null,null);t.default=n.exports}}]);