(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{331:function(e,t,o){"use strict";o.r(t);var r=o(13),a=Object(r.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"find-hits-group-hits"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#find-hits-group-hits"}},[e._v("#")]),e._v(" Find hits / group hits")]),e._v(" "),t("p",[e._v("Find occurrences of a text pattern in the corpus, optionally filtered on document metadata fields.")]),e._v(" "),t("p",[e._v("This resource can also group hits (returning a list of groups), or show the contents of one of the resulting groups.")]),e._v(" "),t("p",[e._v("This is generally the most-used endpoint for BlackLab Server, and includes the most features.  For a more gentle introduction, see the "),t("RouterLink",{attrs:{to:"/server/overview.html"}},[e._v("overview")]),e._v(".")],1),e._v(" "),t("p",[t("strong",[e._v("URL")]),e._v(" : "),t("code",[e._v("/blacklab-server/<corpus-name>/hits")])]),e._v(" "),t("p",[t("strong",[e._v("Method")]),e._v(" : "),t("code",[e._v("GET")])]),e._v(" "),t("p",[e._v("All parameters except "),t("code",[e._v("patt")]),e._v(" are optional.")]),e._v(" "),t("h4",{attrs:{id:"basic-parameters"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#basic-parameters"}},[e._v("#")]),e._v(" Basic parameters")]),e._v(" "),t("p",[e._v("Use these to find text patterns in the corpus and control which results are returned.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Parameter")]),e._v(" "),t("th",[e._v("Description")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("patt")])]),e._v(" "),t("td",[t("RouterLink",{attrs:{to:"/guide/corpus-query-language.html"}},[e._v("BlackLab Corpus Query Language")]),e._v(" (BCQL) pattern to search for")],1)]),e._v(" "),t("tr",[t("td",[t("code",[e._v("filter")])]),e._v(" "),t("td",[t("a",{attrs:{href:"https://lucene.apache.org/core/8_8_1/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package.description",target:"_blank",rel:"noopener noreferrer"}},[e._v("Lucene Query Language"),t("OutboundLink")],1),e._v(" document filter query")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("context")])]),e._v(" "),t("td",[e._v("(formerly "),t("code",[e._v("wordsaroundhit")]),e._v(") how much context to return around hits. Examples: "),t("code",[e._v("5")]),e._v(" gives 5 words around hit, "),t("code",[e._v("5:10")]),e._v(" gives 5 before and 10 after, "),t("code",[e._v("s")]),e._v(" returns full sentences (if "),t("code",[e._v("s")]),e._v(" is an inline tag in your data). Default: "),t("code",[e._v("5")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("first")])]),e._v(" "),t("td",[e._v("first result (0-based) to return with this request. Use this to get a page of results from the total set. Default: "),t("code",[e._v("0")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("number")])]),e._v(" "),t("td",[e._v("number of results to return (if available) with this request. Use this to get a page of results from the total set. Default: "),t("code",[e._v("50")]),e._v("."),t("br"),t("strong",[e._v("NOTE:")]),e._v(" this value is limited by the "),t("RouterLink",{attrs:{to:"/server/configuration.html#complete-config-file"}},[t("code",[e._v("parameters.pageSize.max")]),e._v(" setting")]),e._v(" in "),t("code",[e._v("blacklab-server.yaml")]),e._v("."),t("br"),t("strong",[e._v("NOTE2:")]),e._v(" if you are only interested in the total number of results, not the results themselves, set this to 0. The total number of results will be in the response as "),t("code",[e._v("summary.numberOfHits")]),e._v(".")],1)])])]),e._v(" "),t("h4",{attrs:{id:"parameters-for-sampling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#parameters-for-sampling"}},[e._v("#")]),e._v(" Parameters for sampling")]),e._v(" "),t("p",[e._v("Take a random sampling of hits. Note that this has to retrieve all hits (or at least as many hits as the "),t("code",[e._v("maxretrieve")]),e._v(" setting allows), then perform the sampling, so it may take a while.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Parameter")]),e._v(" "),t("th",[e._v("Description")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("sample")])]),e._v(" "),t("td",[e._v("Percentage of hits to select. Chooses a random sample of all the hits found.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("samplenum")])]),e._v(" "),t("td",[e._v("Exact number of hits to select. Chooses a random sample of all the hits found.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("sampleseed")])]),e._v(" "),t("td",[e._v("Signed long seed number for sampling. If given, uses this value to seed the random number generator, ensuring identical sampling results next time. Please note that, without sorting, hit order is undefined (if the same data is re-indexed, hits may be produced in a different order). So if you want true reproducability, you should always sort hits that you want to sample, ideally with multiple sort criteria so the sort is fully defined.")])])])]),e._v(" "),t("h4",{attrs:{id:"parameters-for-sorting-and-grouping-hits-and-faceting-documents"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#parameters-for-sorting-and-grouping-hits-and-faceting-documents"}},[e._v("#")]),e._v(" Parameters for sorting and grouping hits and faceting documents")]),e._v(" "),t("p",[e._v("Hits can be grouped by various criteria (see below). Faceting can be performed on the matching documents.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Parameter")]),e._v(" "),t("th",[e._v("Description")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("sort")])]),e._v(" "),t("td",[e._v("One or more sort criteria, for example: "),t("code",[e._v("hit:word:s")]),e._v(" to sort by matched words, case-sensitively. Detailed explanation below.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("group")])]),e._v(" "),t("td",[e._v("One or more grouping criteria, for example: "),t("code",[e._v("before:lemma:i:1")]),e._v(" to group on the lemma before the matched words, case-insensitively. Detailed explanation below.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("includegroupcontents")])]),e._v(" "),t("td",[e._v("Whether to include the hits with each group."),t("br"),t("strong",[e._v("NOTE:")]),e._v(" only works for "),t("code",[e._v("/hits")]),e._v(" requests for now. Default: "),t("code",[e._v("false")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("viewgroup")])]),e._v(" "),t("td",[e._v("Identity of one of the groups to view ("),t("code",[e._v("identity")]),e._v(" values are returned with the grouping results)."),t("br"),t("strong",[e._v("NOTE:")]),e._v(" may not return all hits in the group because there is a limit to how many are stored. Use "),t("code",[e._v("hitfiltercrit")]),e._v("/"),t("code",[e._v("hitfilterval")]),e._v(" to get all hits.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("hitfiltercrit")]),e._v(" and "),t("code",[e._v("hitfilterval")])]),e._v(" "),t("td",[e._v("Filter hits by a criterium and value. See below.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("facets")])]),e._v(" "),t("td",[e._v("Document faceting criteria, comma-separated. For example: "),t("code",[e._v("field:author")]),e._v(" to facet matched documents by author. Detailed explanation below.")])])])]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[t("b",[e._v("The "),t("code",[e._v("hitfiltercrit")]),e._v(" / "),t("code",[e._v("hitfilterval")]),e._v(" parameters explained")])]),e._v(" "),t("p",[e._v('These parameters can be used to view all hits in a "group", and even perform another grouping on the results. For example: '),t("code",[e._v("after:pos:i:1")]),e._v(" to filter hits by the "),t("code",[e._v("pos")]),e._v(" value directly following the hit, case-insensitively. Detailed explanation below. Also needs "),t("code",[e._v("hitfilterval")]),e._v(" (the value to keep when filtering) to work.")]),e._v(" "),t("p",[e._v("This is useful if you want to view hits in a group, and then be able to group on those hits again. These two parameters essentially do something similar to the "),t("code",[e._v("viewgroup")]),e._v(" parameter: that parameter also allows you to view the hits in a group, but won't allow you to group that subset of hits again. By specifying multiple criteria and values to "),t("code",[e._v("hitfiltercrit")]),e._v("/"),t("code",[e._v("hitfilterval")]),e._v(", you can keep diving deeper into your result set.")]),e._v(" "),t("p",[e._v("Note that this may be slow at present because it finds all hits, then filters them by this criterium.")]),e._v(" "),t("p",[e._v("(TECHNICAL NOTE: performance could be improved by internally extending the specified "),t("code",[e._v("patt")]),e._v(" with the "),t("code",[e._v("hitfiltercrit")]),e._v("/"),t("code",[e._v("hitfilterval")]),e._v(" so we only find the matches we're interested in, but this requires lookahead/lookbehind to be implemented).")])]),e._v(" "),t("div",{staticClass:"custom-block warning"},[t("p",{staticClass:"custom-block-title"},[e._v("PLEASE NOTE")]),e._v(" "),t("p",[t("code",[e._v("sort")]),e._v(", "),t("code",[e._v("group")]),e._v(" and "),t("code",[e._v("hitfiltercrit")]),e._v("/"),t("code",[e._v("hitfilterval")]),e._v(" all require all results to be retrieved (or at least as much as allowed by the "),t("code",[e._v("maxretrieve")]),e._v(" value), so they may take a lot of time and memory.")])]),e._v(" "),t("p",[e._v('Criteria for sorting, grouping and faceting are explained in "Criteria for sorting, grouping and faceting" below.')]),e._v(" "),t("h4",{attrs:{id:"criteria-for-sorting-grouping-and-faceting"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#criteria-for-sorting-grouping-and-faceting"}},[e._v("#")]),e._v(" Criteria for sorting, grouping and faceting")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("sort")]),e._v(", "),t("code",[e._v("group")]),e._v(", "),t("code",[e._v("hitfiltercrit")]),e._v(" and "),t("code",[e._v("facets")]),e._v(" parameters receive one or more criteria (comma-separated) that indicate what to sort, group, filter or facet on.")]),e._v(" "),t("p",[e._v("These are the basic criteria:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Criterium")]),e._v(" "),t("th",[e._v("Meaning")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("field:"),t("em",[e._v("name")])])]),e._v(" "),t("td",[e._v("Metadata field. Example: "),t("code",[e._v("field:author")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("decade:"),t("em",[e._v("name")])])]),e._v(" "),t("td",[e._v("Sort/group by the decade of the year given in specified metadata field (rounds the value of the field down to the nearest multiple of 10, so "),t("code",[e._v("1976")]),e._v(" becomes "),t("code",[e._v("1970")]),e._v(").")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("identity")])]),e._v(" "),t("td",[e._v("(for sorting results of a grouping request) Sort by group identity.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("size")])]),e._v(" "),t("td",[e._v("(for sorting results of a grouping request) Sort by group size, descending by default.")])])])]),e._v(" "),t("p",[e._v("Any sort criterium can be reversed by prefixing it with a dash, e.g. "),t("code",[e._v("-field:year")]),e._v(" to sort by the "),t("code",[e._v("year")]),e._v(" field, descending. If multiple properties are combined with commas, each may be individually reversed or not, e.g. "),t("code",[e._v("-prop1,prop2,-prop3")]),e._v(" to only reverse "),t("code",[e._v("prop1")]),e._v(" and "),t("code",[e._v("prop3")]),e._v(". It is also possible to reverse all properties together: "),t("code",[e._v("-(prop1,prop2,prop3)")]),e._v(".")]),e._v(" "),t("p",[e._v("In addition to the basic criteria, it is also possible to sort/group on context words, such as the words matched by your query, or the words before or after the matched words:")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Criterium")]),e._v(" "),t("th",[e._v("Meaning")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("hit:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")])])]),e._v(" "),t("td",[e._v("Sort/group/facet on matched text. If "),t("code",[e._v("annot")]),e._v(" is omitted, the default annotation (usually "),t("code",[e._v("word")]),e._v(") is used. "),t("code",[e._v("c")]),e._v(" can specify case-sensitivity: either "),t("code",[e._v("s")]),e._v(" (sensitive) or "),t("code",[e._v("i")]),e._v(" (insensitive). Examples: "),t("code",[e._v("hit")]),e._v(", "),t("code",[e._v("hit:lemma")]),e._v(", "),t("code",[e._v("hit:lemma:s")]),e._v(".")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("before:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("n")])]),t("br"),t("code",[e._v("left:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("n")])])]),e._v(" "),t("td",[e._v("Context words before the hit (if number "),t("code",[e._v("n")]),e._v(" not specified, uses default before-hit context size). For grouping, you might use "),t("code",[e._v("n==1")]),e._v(", and for sorting a larger value (or the default, usually "),t("code",[e._v("5")]),e._v(") might be more suitable. Examples: "),t("code",[e._v("before")]),e._v(", "),t("code",[e._v("before:pos")]),e._v(", "),t("code",[e._v("before:pos:s")]),e._v(", "),t("code",[e._v("before:pos:s:3")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("after:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("n")])]),t("br"),t("code",[e._v("right:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("n")])])]),e._v(" "),t("td",[e._v("Context words after the hit (if number "),t("code",[e._v("n")]),e._v(" not specified, uses default after-hit context size). For grouping, you might use "),t("code",[e._v("n==1")]),e._v(", and for sorting a larger value (or the default, usually "),t("code",[e._v("5")]),e._v(") might be more suitable. Examples: "),t("code",[e._v("after")]),e._v(", "),t("code",[e._v("after:pos")]),e._v(", "),t("code",[e._v("after:pos:s")]),e._v(", "),t("code",[e._v("after:pos:s:3")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("wordleft:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")])])]),e._v(" "),t("td",[e._v("Single word of before-context. Deprecated, use "),t("code",[e._v("before:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":1")]),e._v(" instead.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("wordright:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")])])]),e._v(" "),t("td",[e._v("Single word of after-context. Deprecated, use "),t("code",[e._v("after:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":1")]),e._v(" instead.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("context:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("spec")])])]),e._v(" "),t("td",[e._v("More generic context words expression, giving the user more control at the cost of a bit of speed. Example: "),t("code",[e._v("context:word:s:H1-2")]),e._v(" (first two matched words). See below for a complete specification.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("capture:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("groupname")])]),t("br"),t("code",[e._v("capture:"),t("em",[e._v("annot")]),e._v(":"),t("em",[e._v("c")]),e._v(":"),t("em",[e._v("groupname")]),e._v(":"),t("em",[e._v("spanmode")])])]),e._v(" "),t("td",[e._v("Contents of a named capture group in your text pattern. Example: "),t("code",[e._v("capture:word:s:PERSON")]),e._v(" for the contents of the capture group named "),t("code",[e._v("PERSON")]),e._v(" (your pattern might be "),t("code",[e._v('"talk" "to" PERSON:[]')]),e._v("). "),t("br"),t("br"),e._v("When grouping by matched (dependency) relations, (i.e. with query "),t("code",[e._v("_ -nsubj-> _")]),e._v(" to find subject relations), you can add "),t("code",[e._v("source")]),e._v(" or "),t("code",[e._v("target")]),e._v(" as the "),t("code",[e._v("spanmode")]),e._v(" to group by either the source or target of the relation (default "),t("code",[e._v("spanmode")]),e._v(" is "),t("code",[e._v("full")]),e._v(", which for relations spans both source and target).")])])])]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[t("b",[e._v("The "),t("code",[e._v("context")]),e._v(" criterium explained")])]),e._v(" "),t("p",[e._v("Criteria like "),t("code",[e._v("context:word:s:H1-2")]),e._v(' ("the first two matched words") allow fine control over what to group or sort on.')]),e._v(" "),t("p",[e._v("Like with criteria such as "),t("code",[e._v("left")]),e._v(", "),t("code",[e._v("right")]),e._v(" or "),t("code",[e._v("hit")]),e._v(", you can vary the annotation to group or sort on (e.g. "),t("code",[e._v("word")]),e._v("/"),t("code",[e._v("lemma")]),e._v("/"),t("code",[e._v("pos")]),e._v(", or whatever annotations your data set has). You may specify whether to sort/group case- and accent-sensitively ("),t("code",[e._v("s")]),e._v(") or insensitively ("),t("code",[e._v("i")]),e._v(").")]),e._v(" "),t("p",[e._v("The final parameter to a "),t("code",[e._v("context")]),e._v(' criterium is the "specification". This consists of one or more parts separated by a semicolon. Each part consists of an "anchor" (starting point) and number(s) to indicate a stretch of words. The anchor can be '),t("code",[e._v("H")]),e._v(" (hit text), "),t("code",[e._v("E")]),e._v(" (hit text, but counted from the end of the hit backwards), "),t("code",[e._v("L")]),e._v(" (words to the left of the hit) or "),t("code",[e._v("R")]),e._v(" (words to the right of the hit). The number or numbers after the anchor specify what words you want from this part. A single number indicates a single word; "),t("code",[e._v("1")]),e._v(" is the first word, "),t("code",[e._v("2")]),e._v(" the second word, etc. So "),t("code",[e._v("E2")]),e._v(' means "the second-to-last word of the hit". Two numbers separated by a dash indicate a stretch of words. So '),t("code",[e._v("H1-2")]),e._v(' means "the first two words of the hit", and '),t("code",[e._v("E2-1")]),e._v(' means "the second-to-last word followed by the last word". A single number followed by a dash means "as much as possible from this part, starting from this word". So '),t("code",[e._v("H2-")]),e._v(' means "the entire hit text except the first word".')]),e._v(" "),t("p",[e._v("A few more examples:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("context:word:s:H1;E1")]),e._v(": the first and last matched word)")]),e._v(" "),t("li",[t("code",[e._v("context:word:s:A2-3")]),e._v(": second and third word after the match)")]),e._v(" "),t("li",[t("code",[e._v("context:word:s:B1-")]),e._v(": words before the match, starting from first word before the match, i.e. the same as "),t("code",[e._v("before:word:s")]),e._v(". How many words of context are used depends on the "),t("code",[e._v("context")]),e._v(" parameter (default: 5)")])])]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[e._v("Parallel corpora and grouping/sorting on context")]),e._v(" "),t("p",[e._v("In parallel corpora, you can add an extra parameter at the end of a context\ncriterium like "),t("code",[e._v("hit")]),e._v(" or "),t("code",[e._v("before")]),e._v(" to specify what version you're referring to.")]),e._v(" "),t("p",[e._v("For example, if your parallel corpus has versions "),t("code",[e._v("en")]),e._v(" and "),t("code",[e._v("nl")]),e._v(", you can\nspecify "),t("code",[e._v("hit:word:s:en")]),e._v(" to sort/group on the English version of the matched\ntext, or "),t("code",[e._v("before:word:s:1:nl")]),e._v(" to sort/group on the Dutch version of the word.")])]),e._v(" "),t("h4",{attrs:{id:"miscellaneous-parameters"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#miscellaneous-parameters"}},[e._v("#")]),e._v(" Miscellaneous parameters")]),e._v(" "),t("p",[e._v("Some less commonly used parameters for advanced use cases.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Parameter")]),e._v(" "),t("th",[e._v("Description")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[t("code",[e._v("waitfortotal")])]),e._v(" "),t("td",[e._v("Whether or not to wait for the total number of results to be known. If no (the default), subsequent requests (with number=0 if you donâ€™t need more hits) can be used to monitor the total count progress. Default: "),t("code",[e._v("false")])])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("listvalues")])]),e._v(" "),t("td",[e._v("Comma-separated list of annotation names to return for each result. By default, all annotations are included.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("field")])]),e._v(" "),t("td",[e._v("the annotated field to search using "),t("code",[e._v("patt")]),e._v(", if your corpus contains multiple annotated fields. Most corpora only contain one. Defaults to the first (or only) annotated field defined. (NOTE: for a parallel corpus, if you only specify a version, e.g. "),t("code",[e._v("en")]),e._v(", BlackLab will automatically use the "),t("code",[e._v("contents__en")]),e._v(" field if that exists)")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("pattlang")])]),e._v(" "),t("td",[e._v("pattern language to use for "),t("code",[e._v("patt")]),e._v(". Defaults to "),t("code",[e._v("bcql")]),e._v(" (BlackLab Corpus Query Language). The other values ("),t("code",[e._v("contextql")]),e._v(" and "),t("code",[e._v("luceneql")]),e._v(") have very limited support at the moment.  Other, more useful query languages may be added in the future.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("pattgapdata")])]),e._v(" "),t("td",[e._v("Data (TSV, tab-separated values) to put in gaps in query. Explained below.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("filterlang")])]),e._v(" "),t("td",[e._v("filter language to use for "),t("code",[e._v("filter")]),e._v(". Defaults to "),t("code",[e._v("luceneql")]),e._v(". "),t("code",[e._v("contextql")]),e._v(" is also supported, but very limited. More options may be added in the future.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("docpid")])]),e._v(" "),t("td",[e._v("filter on a single document pid.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("maxretrieve")])]),e._v(" "),t("td",[e._v("Maximum number of hits to retrieve. "),t("code",[e._v("-1")]),e._v(' means "no limit". Also affects documents-containing-pattern queries and grouped-hits queries. Default and maximum allowed value configurable. Very large values (millions, or unlimited) may cause server problems.')])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("maxcount")])]),e._v(" "),t("td",[e._v("Maximum number of hits to count. "),t("code",[e._v("-1")]),e._v(' means "no limit". Default and maximum allowed value configurable. Even when BlackLab stops retrieving hits, it still keeps counting them. For large results sets this may take a long time.')])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("usecontent")])]),e._v(" "),t("td",[t("code",[e._v("fi")]),e._v(" or "),t("code",[e._v("orig")]),e._v(". "),t("code",[e._v("fi")]),e._v(" (default) uses the forward index to reconstruct document content (for snippets and concordances; inline tags are lost in the process), "),t("code",[e._v("orig")]),e._v(" uses the original XML from the content store (slower but more accurate)."),t("br"),t("strong",[e._v("NOTE:")]),e._v(" using the original content may cause problems with well-formedness; these are fixed automatically, but the fix may result in inline tags in strange places (e.g. a start-sentence tag that is not at the start of the sentence anymore)")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("escapexmlfragment")])]),e._v(" "),t("td",[e._v("when using "),t("code",[e._v("usecontent=orig")]),e._v(" and XML response, should fragments be escaped as CDATA or not? Default: "),t("code",[e._v("false")]),e._v(" for API v4 and older, "),t("code",[e._v("true")]),e._v(" for v5+.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("calc")])]),e._v(" "),t("td",[e._v("specify the value "),t("code",[e._v("colloc")]),e._v(" to calculate collocations (frequency lists of words near hits). Experimental feature.")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("omitemptycaptures")])]),e._v(" "),t("td",[e._v("if true, will omit capture groups of length 0 (default "),t("code",[e._v("false")]),e._v(", configurable in blacklab-server.yaml)")])]),e._v(" "),t("tr",[t("td",[t("code",[e._v("adjusthits")])]),e._v(" "),t("td",[e._v("(relations queries only) should query hits be adjusted so all matched relations are inside the hit? Default: "),t("code",[e._v("no")])])])])]),e._v(" "),t("details",{staticClass:"custom-block details"},[t("summary",[t("b",[e._v("The "),t("code",[e._v("pattgapdata")]),e._v(" parameter explained")])]),e._v(" "),t("p",[e._v("You may leave 'gaps' in the double-quoted strings in your BCQL query that can be filled in from tabular data. The gaps should be denoted by "),t("code",[e._v("@@")]),e._v(", e.g. "),t("code",[e._v('[lemma="@@"]')]),e._v(" or "),t("code",[e._v('[word="@@cat"]')]),e._v(". For each row in your TSV data, will fill in the row data in the gaps. The queries resulting from all the rows are combined using OR. For example, if your query is "),t("code",[e._v('"The" "@@" "@@"')]),e._v(" and your TSV data is "),t("code",[e._v("white\\tcat\\nblack\\tdog")]),e._v(", this will execute the query "),t("code",[e._v('("The" "white" "cat") | ("The" "black" "dog")')]),e._v(". Please note that if you want to pass a large amount of data, you should use a "),t("code",[e._v("POST")]),e._v(" request as the amount of data you can pass in a "),t("code",[e._v("GET")]),e._v(" request is limited.")])]),e._v(" "),t("h2",{attrs:{id:"success-response"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#success-response"}},[e._v("#")]),e._v(" Success Response")]),e._v(" "),t("p",[t("strong",[e._v("Code")]),e._v(" : "),t("code",[e._v("200 OK")])]),e._v(" "),t("h3",{attrs:{id:"content-examples"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#content-examples"}},[e._v("#")]),e._v(" Content examples")]),e._v(" "),t("p",[e._v("TODO")]),e._v(" "),t("div",{staticClass:"language-json extra-class"},[t("pre",{pre:!0,attrs:{class:"language-json"}},[t("code",[e._v("\n")])])]),t("h2",{attrs:{id:"todo"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#todo"}},[e._v("#")]),e._v(" TODO")]),e._v(" "),t("ul",[t("li",[e._v("This endpoint does a lot of different things, producing different responses. This can be confusing. We could consider moving the grouping operations to one or more new endpoints.")])])])}),[],!1,null,null,null);t.default=a.exports}}]);