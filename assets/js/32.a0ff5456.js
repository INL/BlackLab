(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{307:function(t,a,s){"use strict";s.r(a);var n=s(13),e=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"input-format-configuration"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#input-format-configuration"}},[t._v("#")]),t._v(" Input format configuration")]),t._v(" "),a("p",[t._v("An input format configuration file describes the structure of your documents so that BlackLab can index them.")]),t._v(" "),a("p",[t._v("They can be used to index data from the commandline using the "),a("RouterLink",{attrs:{to:"/guide/indexing-with-blacklab.html#index-supported-format"}},[t._v("IndexTool")]),t._v("\nor using BlackLab Frontend (configured to allow users to upload and index their own corpora).")],1),t._v(" "),a("p",[t._v("BlackLab already "),a("RouterLink",{attrs:{to:"/guide/indexing-with-blacklab.html#supported-formats"}},[t._v("supports")]),t._v(" a number of common input formats out of the box. Your data may differ slightly of course, so you may use the predefined formats as a starting point and customize them to fit your data.")],1),t._v(" "),a("h2",{attrs:{id:"basics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#basics"}},[t._v("#")]),t._v(" Basics")]),t._v(" "),a("h3",{attrs:{id:"a-simple-example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#a-simple-example"}},[t._v("#")]),t._v(" A simple example")]),t._v(" "),a("p",[t._v("Let's see how to write a configuration file for a simple custom corpus format.")]),t._v(" "),a("p",[t._v("Suppose our tokenized XML files look like this:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("metadata")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("1234"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("How to configure indexing"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("author"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Jan Niestadt"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("description"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Shedding some light on this indexing business!"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("s")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("this"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("PRO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("This"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("be"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("VRB"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("is"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("ART"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("a"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("NOU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("test"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(".\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("s")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- ...more documents... --\x3e")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("Below is the configuration file you would need to index files of this type. This uses "),a("RouterLink",{attrs:{to:"/guide/yaml.html"}},[t._v("YAML")]),t._v(", but you can also use JSON if you prefer.")],1),t._v(" "),a("p",[t._v('Note that the settings with names ending in "Path" are XPath expressions (at least if you\'re parsing XML files - more on other file types later).')]),t._v(" "),a("p",[t._v("For an important note about XPath support, see "),a("a",{attrs:{href:"#xpath-support-level"}},[t._v("XPath support level")]),t._v(" below.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## What element starts a new document?")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //document\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Annotated, CQL-searchable fields")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Document contents")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What element (relative to documentPath) contains this field's contents?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What are our word tags? (relative to containerPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What annotation can each word have? How do we index them?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# (annotations are also called "(word) properties" in BlackLab)')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (valuePaths relative to wordPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# NOTE: forEachPath is NOT allowed for annotations, because we need to know all annotations before indexing,")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#       and with forEachPath you could run in to an unknown new annotation mid-way through.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Text of the <w/> element contains the word form")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (first annotation becomes the main annotation)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# lemma attribute contains the lemma (headword)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@lemma"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pos attribute contains the part of speech")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@pos"')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What tags occurring between the word tags do we wish to index? (relative to containerPath) ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Sentence tags")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//s\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Embedded metadata in document")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What element contains the metadata (relative to documentPath)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What metadata fields do we have?")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <metadata/> tag has an id attribute we want to index as docId")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" docId\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@id"')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Each <meta/> tag corresponds with a metadata field")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forEachPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" meta\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@name"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# name attribute contains field name")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# element text is the field value")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("corpusConfig")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("specialFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What metadata field persistently identifies our documents?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("pidField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" docId\n")])])]),a("p",[t._v("To use this configuration, you should save it with a name like "),a("code",[t._v("simple-input-format.blf.yaml")]),t._v(" ("),a("code",[t._v("blf")]),t._v(" stands for BlackLab Format) in either directory from which you will be using it, or alternatively one of "),a("code",[t._v("$BLACKLAB_CONFIG_DIR/formats/")]),t._v(" (if this environment variable is set), "),a("code",[t._v("$HOME/.blacklab/formats/")]),t._v(" or "),a("code",[t._v("/etc/blacklab/formats/")]),t._v(".")]),t._v(" "),a("p",[t._v("Please note that when declaring annotations, the first annotation you declare will become the "),a("em",[t._v("main annotation")]),t._v(". The main annotation will:")]),t._v(" "),a("ul",[a("li",[t._v("be searched when omitting annotation name in CQL (e.g. search for "),a("code",[t._v('"ship"')]),t._v(" and it searches the main annotation).")]),t._v(" "),a("li",[t._v("be used to generate concordances (the KWIC view).")]),t._v(" "),a("li",[t._v("be returned as the value (text content) of the "),a("code",[t._v("<w>")]),t._v(" tag (in the XML response).")])]),t._v(" "),a("p",[t._v("The rest of this page will address how to accomplish specific things with the input format configuration. For a more complete picture that can serve as a reference, see the "),a("RouterLink",{attrs:{to:"/guide/how-to-configure-indexing.html#annotated-configuration-file"}},[t._v("annotated input format configuration file example")]),t._v(".")],1),t._v(" "),a("h3",{attrs:{id:"xpath-support-level"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#xpath-support-level"}},[t._v("#")]),t._v(" XPath support level")]),t._v(" "),a("p",[t._v("BlackLab supports two different XML processors: VTD and Saxon. While currently VTD is still the default, we would recommend Saxon for most users going forward.")]),t._v(" "),a("p",[t._v("VTD only supports XPath 1.0 and has some slight quirks (see below). Saxon uses more memory, but is often faster and supports XPath 3.1, which can make writing indexing configurations much easier.")]),t._v(" "),a("p",[t._v("Certain "),a("a",{attrs:{href:"https://github.com/INL/BlackLab/issues/447",target:"_blank",rel:"noopener noreferrer"}},[t._v("advanced indexing features"),a("OutboundLink")],1),t._v(" added in the past can be avoided when using Saxon; many things can be done in XPath directly. See "),a("RouterLink",{attrs:{to:"/guide/xpath-examples.html"}},[t._v("XPath examples")]),t._v(" to get an idea of the wide range of possibilities.")],1),t._v(" "),a("p",[t._v("To use Saxon, place this in your input format config (.blf.yaml) file (at the top level):")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("processor")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" saxon\n")])])]),a("p",[t._v("This works for the current development version and releases 4.0 and up.")]),t._v(" "),a("details",{staticClass:"custom-block details"},[a("summary",[t._v("Using Saxon with BlackLab 3.0.1 and older")]),t._v(" "),a("p",[t._v("In older versions of BlackLab (release 3.0.1 and before), there is basic Saxon support, but there are quite a few features missing.")]),t._v(" "),a("p",[t._v("It also didn't support the top-level "),a("code",[t._v("processor")]),t._v(" key shown above; if you do want to use Saxon on these older releases, use:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" xml\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileTypeOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("processing")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" saxon   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (instead of vtd, which is the default)")]),t._v("\n")])])])]),t._v(" "),a("details",{staticClass:"custom-block details"},[a("summary",[t._v("Beware of VTD quirks")]),t._v(" "),a("p",[t._v("If you do stick with the default processor VTD instead of switching to Saxon, be aware that in rare cases, a correct XPath may produce unexpected results. This one for example: "),a("code",[t._v("string(.//tei:availability[1]/@status='free')")]),t._v(". There's often a workaround for this, in this case changing it to "),a("code",[t._v("string(//tei:availability[1]/@status='free')")]),t._v(" might fix it (although of course this means something slightly different, so do check thoroughly).")]),t._v(" "),a("p",[t._v("A future version of BlackLab will change the default from VTD to Saxon.")])]),t._v(" "),a("h3",{attrs:{id:"case-and-diacritics-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#case-and-diacritics-sensitivity"}},[t._v("#")]),t._v(" Case- and diacritics sensitivity")]),t._v(" "),a("p",[t._v('You can also configure what "sensitivity alternatives" (case/diacritics sensitivity) to index for each annotation using the "sensitivity" setting:')]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n")])])]),a("p",[t._v("Valid values for sensitivity are:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("sensitive")]),t._v(" or "),a("code",[t._v("s")]),t._v(": case+diacritics sensitive only")]),t._v(" "),a("li",[a("code",[t._v("insensitive")]),t._v(" or "),a("code",[t._v("i")]),t._v(": case+diacritics insensitive only")]),t._v(" "),a("li",[a("code",[t._v("sensitive_insensitive")]),t._v(" or "),a("code",[t._v("si")]),t._v(": case+diacritics sensitive and insensitive")]),t._v(" "),a("li",[a("code",[t._v("all")]),t._v(": all four combinations of case-sensitivity and diacritics-sensivity")])]),t._v(" "),a("p",[t._v("What alternatives are indexed determines how specifically you can specify the desired sensitivity when searching. Each alternative increases index size.")]),t._v(" "),a("p",[t._v("If you don't configure an annotation's "),a("code",[t._v("sensitivity")]),t._v(" parameter, it will default to "),a("code",[t._v("insensitive")]),t._v(".")]),t._v(" "),a("p",[t._v("There is one exception: annotations named "),a("code",[t._v("word")]),t._v(" or "),a("code",[t._v("lemma")]),t._v(" default to "),a("code",[t._v("sensitive_insensitive")]),t._v(" for now. This special behaviour is deprecated though, and will be removed eventually. It's best to explicitly declare a "),a("code",[t._v("sensitivity")]),t._v(" for these two annotations so this future change won't impact you.")]),t._v(" "),a("h3",{attrs:{id:"spans-inline-tags"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spans-inline-tags"}},[t._v("#")]),t._v(" Spans (inline tags)")]),t._v(" "),a("p",[t._v('As you can see in the example above, we\'ve configured an "inline tag" or span annotation. It captures the '),a("code",[t._v("<s/>")]),t._v(" elements in the input document and indexes them as spans.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What tags occurring between the word tags do we wish to index? (relative to containerPath) ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Sentence tags")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//s\n")])])]),a("p",[t._v("This means we can later run searches like:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v('"oak" "tree" within <s/>\n')])])]),a("p",[t._v("(more about matching spans "),a("RouterLink",{attrs:{to:"/guide/corpus-query-language.html#matching-xml-elements"}},[t._v("here")]),t._v(")")],1),t._v(" "),a("p",[t._v("There's a few additional parameters you can set for inline tags (provided your "),a("code",[t._v(".blf.yaml")]),t._v(" file uses "),a("code",[t._v("processor: saxon")]),t._v(" instead of the (current) default VTD):")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What tags occurring between the word tags do we wish to index? (relative to containerPath) ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Sentence tags")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//s\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("excludeAttributes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Don't index Unique ids unless you need them; ")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# they slow down indexing and searching and increase index size")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"xml:id"')]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//p\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("includeAttributes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Only index this tag's type attribute")]),t._v("\n        \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Any extra attributes to index with this tag using XPath")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("extraAttributes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# if e.g. input is <p xml:id="par-12">...</p> , index  number="12"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"number"')]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"substring-after(@xml:id, 'par-')\"")]),t._v("\n          \n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//ne\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayAs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" named"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("entity    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# what CSS class to use (when using autogenerated XSLT)    ")]),t._v("\n")])])]),a("p",[t._v("As you can see, "),a("code",[t._v("excludeAttributes")]),t._v(" can be used to prevent the index size ballooning because of a unique id (although of course you won't be able to search sentences by their id anymore), and "),a("code",[t._v("displayAs")]),t._v(" can be used to give the span a different CSS class in the generated XSLT (see "),a("a",{attrs:{href:"#automatic-xslt-generation"}},[t._v("Automatic XSLT generation")]),t._v(").")]),t._v(" "),a("h3",{attrs:{id:"document-metadata"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#document-metadata"}},[t._v("#")]),t._v(" Document metadata")]),t._v(" "),a("p",[t._v("The basic overview (see above) included a way to index embedded metadata. Let's say this is our input file:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- ... document contents... --\x3e")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("metadata")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("1234"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("How to configure indexing"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("author"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Jan Niestadt"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("meta")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("description"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Shedding some light on this indexing business!"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("meta")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v('To configure how metadata should be indexed, you can either name each metadata field you want to index separately, or you can use "forEachPath" to index a number of similar elements as metadata:')]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Embedded metadata in document")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What element contains the metadata (relative to documentPath)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What metadata fields do we have?")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <metadata/> tag has an id attribute we want to index as docId")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" docId\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@id"')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Each <meta/> tag corresponds with a metadata field")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forEachPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" meta\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@name"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# name attribute contains field name")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# element text is the field value")]),t._v("\n")])])]),a("p",[t._v("It's also possible to process metadata values before they are indexed (see "),a("a",{attrs:{href:"#processing-values"}},[t._v("Processing values")]),t._v("), although it's often preferable to do as much processing as possible in XPath.")]),t._v(" "),a("h4",{attrs:{id:"tokenize-or-not"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tokenize-or-not"}},[t._v("#")]),t._v(" Tokenize or not?")]),t._v(" "),a("p",[t._v("By default, metadata fields are tokenized, but it can sometimes be useful to index a metadata field without tokenizing it. One example of this is a field containing the document id: if your document ids contain characters that normally would indicate a token boundary, like a period (.) , your document id would be split into several tokens, which is usually not what you want.")]),t._v(" "),a("p",[t._v("To prevent a metadata field from being tokenized:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# This field should not be split into words")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" docId\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" @docId\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" untokenized\n")])])]),a("h3",{attrs:{id:"allow-viewing-documents"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#allow-viewing-documents"}},[t._v("#")]),t._v(" Allow viewing documents")]),t._v(" "),a("p",[t._v("By default, BlackLab Server will not allow whole documents to be retrieved using "),a("code",[t._v("/docs/PID/contents")]),t._v(". This is to prevent accidentally distributing unlicensed copyrighted material.")]),t._v(" "),a("p",[t._v("You can allow retrieving whole documents by enabling the "),a("code",[t._v("corpusConfig.contentViewable")]),t._v(" setting in the index format configuration file, or directly in the "),a("code",[t._v("indexmetadata.yaml")]),t._v(" file in the index directory. Also see the next section.")]),t._v(" "),a("p",[t._v("This setting can also be changed for individual documents by setting a metadat field with the name "),a("code",[t._v("contentViewable")]),t._v(" to "),a("code",[t._v("true")]),t._v(" or "),a("code",[t._v("false")]),t._v(".")]),t._v(" "),a("h2",{attrs:{id:"intermediate"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#intermediate"}},[t._v("#")]),t._v(" Intermediate")]),t._v(" "),a("h3",{attrs:{id:"handling-part-of-speech-features-subannotations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#handling-part-of-speech-features-subannotations"}},[t._v("#")]),t._v(" Handling Part of Speech features (subannotations)")]),t._v(" "),a("p",[t._v('Part of speech sometimes consists of several features in addition to the main PoS, e.g. "NOU-C(gender=n,number=sg)". It would be nice to be able to search each of these features separately without resorting to complex regular expressions. BlackLab supports subannotations to achieve this.')]),t._v(" "),a("blockquote",[a("p",[t._v("Note that this feature is still (somewhat) experimental and details may change in future versions.")])]),t._v(" "),a("p",[t._v("Suppose your XML looks like this:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Veel"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("pos")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("VNW(onbep,grad)"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("head")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("ADJ"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("feat")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("onbep"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subset")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("lwtype"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("feat")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("grad"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subset")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("pdtype"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("pos")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("veel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("gedaan"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("pos")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("WW(vd,zonder)"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("head")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("WW"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("feat")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("vd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subset")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("wvorm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("feat")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("zonder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("subset")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("buiging"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("pos")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("doen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("Here's how to define subannotations:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //document\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w\n\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" t\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma/@class\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("basePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos         "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# "base element" to match for this annotation.')]),t._v("\n                            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (other XPath expressions for this annotation are relative to this)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@class"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# main value for the annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("subannotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("       "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# structure of each subannotation is the same as a regular annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" head         \n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@head"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# "main" part of speech is found in head attribute of <pos/> element')]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# forEachPath will get the name and value of a set of annotations from just two xpaths.")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# However you still need to declare all names in this config!")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If it encounters an unknown name a warning will be emitted.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forEachPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feat"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# other features are found in <feat/> elements")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@subset"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# subset attribute contains the subannotation name")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@class"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# class attribute contains the subannotation value")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# now declare the expected names. See the example document above.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the forEachPath makes it so we don't have to repeatedly set the valuePath with specific attribute qualifiers here.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lwtype\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pdtype\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" wvorm\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" buiging\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Fully written out the above is equal to:")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If there are many of these qualifiers, the forEach construction will probably also perform a little better.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lwtype\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@subset='lwtype'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pdtype\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@subset='pdtype'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" wvorm\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@subset='wvorm'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" buiging\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" feat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@subset='buiging'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n")])])]),a("p",[t._v("Adding a few subannotations per token position like this will make the index slightly larger, but it shouldn't affect performance or index size too much.")]),t._v(" "),a("h3",{attrs:{id:"standoff-annotations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#standoff-annotations"}},[t._v("#")]),t._v(" Standoff annotations")]),t._v(" "),a("p",[t._v("Standoff annotations are annotations that are specified in a different part of the document.\nFor example:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("This"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("is"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("a"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("test"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(".\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("standoff")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("annotation")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ref")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("this"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("PRO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("annotation")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ref")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("be"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("VRB"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("annotation")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ref")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("ART"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("annotation")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ref")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("p4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("lemma")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("pos")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("NOU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("standoff")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("To index these types of annotations, use a configuration like this one:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //document\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If specified, the token position for each id will be saved,")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# so you can index standoff annotations referring to this id later.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenIdPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@id"')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("standoffAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" standoff/annotation      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Element containing what to index (relative to containerPath)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenRefPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@ref"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What token position(s) to index these values at")]),t._v("\n                                     "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (may have multiple matches per path element; values will ")]),t._v("\n                                     "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# be indexed at all those positions)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("           "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The actual annotations (structure identical to regular annotations)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@lemma"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@pos"')]),t._v("\n")])])]),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("Try using XPath instead")]),t._v(" "),a("p",[t._v("it is often also possible to achieve the same effect using XPath expressions in the valuePath of a regular annotation, espcially when using Saxon as your XML processor. Where possible, this is recommended.")]),t._v(" "),a("p",[t._v("This approach doesn't work for spans (inline tags) and relations though; read on for those.")])]),t._v(" "),a("h4",{attrs:{id:"standoff-annotations-for-spans-inline-tags"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#standoff-annotations-for-spans-inline-tags"}},[t._v("#")]),t._v(" Standoff annotations for spans (inline tags)")]),t._v(" "),a("p",[t._v("The default standoff annotations as shown above apply an annotation to a single token (or several tokens, but each get the annotation value separately). What if instead you want to define a span of tokens?")]),t._v(" "),a("p",[t._v("(you can also do this with "),a("code",[t._v("inlineTags")]),t._v(", but that relies on the tags being part of the document contents, e.g. "),a("code",[t._v("<p/>")]),t._v(" or "),a("code",[t._v("<s/>")]),t._v(", and prevents you from having partially overlapping spans)")]),t._v(" "),a("p",[t._v("This is possible using "),a("code",[t._v("spanStartPath")]),t._v(", "),a("code",[t._v("spanEndPath")]),t._v(" and "),a("code",[t._v("spanNamePath")]),t._v(" (instead of "),a("code",[t._v("tokenRefPath")]),t._v(" used above). So to index this XML:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("The"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("quick"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("brown"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("fox"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("jumps"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w6"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("over"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    ...\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("span")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("from")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("to")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("animal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("speed")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("fast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("You can use this "),a("code",[t._v("standoffAnnotations")]),t._v(" configuration:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenIdPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@xml:id"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("standoffAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//span\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanStartPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@from"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanEndPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@to"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanEndIsInclusive")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanNamePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@type"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" speed\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@speed"')]),t._v("\n")])])]),a("p",[t._v("Note the setting "),a("code",[t._v("spanEndIsInclusive: true")]),t._v(" to indicate that the "),a("code",[t._v("to")]),t._v(" attribute refers to the last token of the span, not the first token "),a("em",[t._v("after")]),t._v(" the span. ("),a("code",[t._v("true")]),t._v(" is the default value for this setting, but it is included here for completeness)")]),t._v(" "),a("p",[t._v("The above would allow you to search for "),a("code",[t._v('<animal/> containing "fox"')]),t._v(" or "),a("code",[t._v('<animal speed="fast" />')]),t._v(' to find "The quick brown fox".')]),t._v(" "),a("h4",{attrs:{id:"standoff-annotations-for-relations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#standoff-annotations-for-relations"}},[t._v("#")]),t._v(" Standoff annotations for relations")]),t._v(" "),a("p",[t._v("See "),a("a",{attrs:{href:"#indexing-dependency-relations"}},[t._v("Indexing (dependency) relations")]),t._v(" below.")]),t._v(" "),a("h4",{attrs:{id:"referring-to-inline-anchors-instead-of-words"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#referring-to-inline-anchors-instead-of-words"}},[t._v("#")]),t._v(" Referring to inline anchors instead of words")]),t._v(" "),a("p",[t._v('Normally, standoff annotations refer to token ("word") ids, defined by the '),a("code",[t._v("tokenIdPath")]),t._v(" setting at the annotated field level.")]),t._v(" "),a("p",[t._v("But what if your XML includes inline anchor tags between words that you want to\nrefer to? For example:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("anchor")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("The"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("quick"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("brown"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("fox"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("anchor")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("there"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("jumps"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w6"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("over"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    ...\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("span")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("from")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("to")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("there"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("animal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("speed")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("fast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("Use this configuration for this situation:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Capture the anchor ids.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (each anchor id will point to the token FOLLOWING the anchor!)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ./anchor\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenIdPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@id"')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("standoffAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//span\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanStartPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@from"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanEndPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@to"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanEndIsInclusive")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("spanNamePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@type"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" speed\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@speed"')]),t._v("\n")])])]),a("p",[t._v("As you can see, we capture the id of the "),a("code",[t._v("anchor")]),t._v(" tokens and refer to them the same way as word tokens (this does means that ids must be unique in the document!).")]),t._v(" "),a("p",[t._v("Note the use of "),a("code",[t._v("spanEndIsInclusive: false")]),t._v(" because the anchor id that "),a("code",[t._v("to")]),t._v(" refers to will point to the first token "),a("em",[t._v("after")]),t._v(" the span.")]),t._v(" "),a("h4",{attrs:{id:"standoff-annotations-without-a-unique-token-id"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#standoff-annotations-without-a-unique-token-id"}},[t._v("#")]),t._v(" Standoff annotations without a unique token id")]),t._v(" "),a("p",[t._v("There is an alternate way of doing standoff annotations that does not rely on a unique token id like the method described above (although you will need some way to connect the standoff annotation to the word, obviously). This will probably be slower, but in some cases, it may be useful.")]),t._v(" "),a("p",[t._v("Let's say you want to index a color with every word, and your document looks like this:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("colors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("color")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("blue"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("color")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("color")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("green"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("color")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("color")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("red"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("color")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("colors")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("colorId")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("This"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("colorId")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("is"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("colorId")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("a"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("colorId")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("test"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(".\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("A standoff annotation of this type is defined in the same section as regular (non-standoff) annotations. It relies on capturing one or more values to help us locate the color we want to index at each position. These captured values are then substituted in the valuePath that fetches the color value:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" color\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("captureValuePaths")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("                  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# value(s) we need from the current word to find the color")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@colorId"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /root/colors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@id='$1'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# how to get the value for this annotation from the document,")]),t._v("\n                                      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# using the value(s) captured.")]),t._v("\n")])])]),a("h3",{attrs:{id:"indexing-dependency-relations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-dependency-relations"}},[t._v("#")]),t._v(" Indexing (dependency) relations")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("Supported from v4.0")]),t._v(" "),a("p",[t._v("Indexing and searching relations will be supported from BlackLab 4.0 (and current development snapshots).")])]),t._v(" "),a("p",[t._v("It is also possible to index relations (such as dependency relations) using "),a("a",{attrs:{href:"#standoff-annotations"}},[t._v("standoff annotations")]),t._v(". Aside from using the built-in "),a("code",[t._v("conll-u")]),t._v(" DocIndexer, or implementing your own DocIndexer, this is currently the only way to index relations in BlackLab. Standoff annotations make the most sense as relations don't just apply to a span of words, but connect two different words (or word groups).")]),t._v(" "),a("p",[t._v("Please note that the relations features only work with the newer integrated index type. This type is the default now, so you don't need to pass any extra options to BlackLab.")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("s")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("s1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("I"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("support"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("the"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("join")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("amendment"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("pc")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xml:")]),t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("w5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("."),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("pc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("linkGrp")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("targFunc")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("head argument"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("UD-SYN"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("link")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ana")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ud-syn:nsubj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("target")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("#w2 #w1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("link")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ana")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ud-syn:root"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("target")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("#s1 #w2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("link")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ana")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ud-syn:det"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("target")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("#w4 #w3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("link")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ana")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ud-syn:obj"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("target")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("#w2 #w4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("link")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("ana")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("ud-syn:punct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("target")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("#w2 #w5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("linkGrp")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("s")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("You can use this configuration:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //doc\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("processor")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" saxon  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# required to index relations")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namespaces")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("xml")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//www.w3.org/XML/1998/namespace\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Both <w/> and <pc/> tags should be indexed as separate token positions")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("|")]),t._v(".//pc\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If specified, the token position for each id will be saved,")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# so you can index standoff annotations referring to this id later.")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenIdPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@xml:id"')]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("standoffAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//linkGrp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@targFunc='head argument'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("/link\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" relation\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"replace(@ana, 'ud-syn:', '')\"")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# relation type")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Note that we make sure the root relation is indexed without a source, ")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# which is required in BlackLab.")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sourcePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"if (./@ana = 'ud-syn:root') then '' else replace(./@target, '^#(.+) .+$', '$1')\"")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("targetPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"replace(./@target, '^.+ #(.+)$', '$1')\"")]),t._v("\n")])])]),a("p",[t._v("The above would allow you to search for "),a("code",[t._v('_ -nsubj-> "I"')]),t._v(' to find "I support", with the relation information captured. '),a("RouterLink",{attrs:{to:"/guide/corpus-query-language.html#relations-querying"}},[t._v("Learn more about how to query relations")])],1),t._v(" "),a("h3",{attrs:{id:"indexing-parallel-corpora"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-parallel-corpora"}},[t._v("#")]),t._v(" Indexing parallel corpora")]),t._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[t._v("Supported from v4.0")]),t._v(" "),a("p",[t._v("Indexing and searching parallel corpora will be supported from BlackLab 4.0 (and current development snapshots).")])]),t._v(" "),a("p",[t._v("TODO: how to index parallel corpus")]),t._v(" "),a("p",[t._v("If everything worked, you should be able to search for "),a("code",[t._v("<s/> ==>nl <s/>")]),t._v(" to find alignments per sentence between the English and Dutch versions. For more, see "),a("RouterLink",{attrs:{to:"/guide/corpus-query-language.html#parallel-corpus-querying"}},[t._v("parallel corpus querying")]),t._v(".")],1),t._v(" "),a("h3",{attrs:{id:"more-about-document-metadata"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#more-about-document-metadata"}},[t._v("#")]),t._v(" More about document metadata")]),t._v(" "),a("h4",{attrs:{id:"default-gui-widgets"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#default-gui-widgets"}},[t._v("#")]),t._v(" Default GUI widgets")]),t._v(" "),a("p",[t._v("In the "),a("code",[t._v("fields")]),t._v(" section, you can specify "),a("code",[t._v("uiType")]),t._v(" for each field to override the default GUI widget to use for the field. By default, fields that have only a few values will use "),a("code",[t._v("select")]),t._v(", while others will use "),a("code",[t._v("text")]),t._v(". There's also a "),a("code",[t._v("range")]),t._v(" type for a range of numbers.")]),t._v(" "),a("p",[t._v("Example:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uiType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" select\n      \n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" year\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uiType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" range\n      \n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" genre\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uiType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n")])])]),a("h4",{attrs:{id:"add-a-fixed-metadata-value-to-each-document"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-a-fixed-metadata-value-to-each-document"}},[t._v("#")]),t._v(" Add a fixed metadata value to each document")]),t._v(" "),a("p",[t._v("You can add a field with a fixed value to every document indexed. This could be useful if you plan to add several data sets to one index and want to make sure each document is tagged with the data set name. To do this, simply specify "),a("code",[t._v("value")]),t._v(" instead of "),a("code",[t._v("valuePath")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Regular metadata field    ")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Metadata field with fixed value")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" collection\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" blacklab"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("docs\n")])])]),a("h4",{attrs:{id:"linking-to-external-document-metadata"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#linking-to-external-document-metadata"}},[t._v("#")]),t._v(" Linking to external document metadata")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("NOTE:")]),t._v(" this is a rather complex and little-used feature. We may decide to deprecate or change this in the future. See if you can achieve your desired results using the "),a("code",[t._v("document()")]),t._v(" function in XPath with the Saxon XML processor.")])]),t._v(" "),a("p",[t._v("Sometimes, documents link to external metadata sources, usually using an ID. You can configure linking to external files using a top-level element "),a("code",[t._v("linkedDocuments")]),t._v(". If our data looks like this:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("\x3c!-- ... document contents... --\x3e")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("externalMetadata")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("54321"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("And the metadata for this document can be found at http://example.com/metadata?id=54321, this is how to configure the document linking:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Any document(s) we also want to index while indexing this one")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Usually just our external metadata.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkedDocuments")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Name for what this linked document represents; used to choose a field name")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# when storing the document. "metadata" is usually a good choice.')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Should we store the linked document in our index?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (in this case, a field metadataCid will be created that contains a content")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  store id, allowing you to fetch the original content of the document later)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Values we need for locating the linked document")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (matching values will be substituted for $1-$9 below)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The value we need to determine the URL to our metadata")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to documentPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" externalMetadata/@id\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to fetch the linked input file containing the linked document.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# File or http(s) reference. May contain $x (x = 1-9), which will be replaced ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# with linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//example.com/metadata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("?")]),t._v("id=$1\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If the linked input file is an archive (zip is recommended because it allows ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# random access), this is the path inside the archive where the file can be found. ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#pathInsideArchive: some/dir/$1")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Format identifier for indexing the linked file")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFormat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" my"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("metadata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("format\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# XPath to the (single) linked document to process.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If omitted, the entire file is processed, and must contain only one document.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#documentPath: /root/metadata[@docId = $2]")]),t._v("\n")])])]),a("p",[t._v("As you can see, it's possible to use local files or files via http; you can use archives and specify how to find the relevant metadata inside the archive; and if the linked file contains the metadata for multiple documents, you can specify a path to the specific metadata for this document.")]),t._v(" "),a("p",[t._v('Linking to external files is mostly done to fetch metadata to accompany a "contents" file, but there\'s no reason why you couldn\'t turn the tables if you wanted, and index a set of metadata files that link to the corresponding "contents" file. The mechanism is universal; it would even be possible to link to a document that links to another document, although that may not be very useful.')]),t._v(" "),a("h3",{attrs:{id:"corpus-metadata"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#corpus-metadata"}},[t._v("#")]),t._v(" Corpus metadata")]),t._v(" "),a("p",[t._v("Each BlackLab corpus has its own metadata, recording information such as the time the index was generated and the BlackLab version used, plus information about annotations and metadata fields.")]),t._v(" "),a("p",[t._v("Some of this information is generated as part of the indexing process, and some of the information is copied directly from the input format configuration file if specified. This information is mostly used by applications to learn about the structure of the corpus, get human-friendly names for the various parts, and decide what UI widget to show for a metadata field.")]),t._v(" "),a("p",[t._v("The best way to influence the corpus metadata is by including a special section "),a("code",[t._v("corpusConfig")]),t._v(" in your format configuration file. This section may contains certain settings to be copied directly into the index file when it is created:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The settings in this block will be copied into indexmetadata.yaml")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("corpusConfig")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Some basic information about the corpus that may be used by a user interface.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" OpenSonar              "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Corpus name to display in user interface")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" The OpenSonar corpus.  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Corpus description to display in user interface")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contentViewable")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("              "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Is the user allowed to view whole documents? [false]")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("textDirection")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" LTR                  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What's the text direction of this corpus? [LTR]")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Metadata fields with a special meaning")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("specialFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("pidField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" id           "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique persistent identifier, used for document lookups, etc.")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("titleField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" title      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# used to display document title in interface")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("authorField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# used to display author in interface")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dateField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" date        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# used to display document date in interface")]),t._v("\n      \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to group metadata fields in user interface")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadataFieldGroups")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" First group      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Text on tab, if there's more than one group")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Metadata fields to display on this tab")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" author\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" title\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Second group\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" date\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" keywords\n")])])]),a("p",[t._v("If you add "),a("code",[t._v("addRemainingFields: true")]),t._v(" to one of the groups, any field that wasn't explicitly listed will be added to that group.")]),t._v(" "),a("p",[t._v("There's also a complete "),a("RouterLink",{attrs:{to:"/guide/how-to-configure-indexing.html#annotated-configuration-file"}},[t._v("annotated index metadata file")]),t._v(" if you want to know more details about that.")],1),t._v(" "),a("p",[t._v("There are also (hacky) ways to make changes to the corpus metadata after it was indexed: you can export the metadata to a file and re-import it later (older indexes had an external "),a("code",[t._v("indexmetadata.yaml")]),t._v(" file that could be edited directly). Start the "),a("code",[t._v("IndexTool")]),t._v(" with "),a("code",[t._v("--help")]),t._v(" to learn more, but be careful, as it is easy to make the index unusable this way.")]),t._v(" "),a("h3",{attrs:{id:"reducing-index-size"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reducing-index-size"}},[t._v("#")]),t._v(" Reducing index size")]),t._v(" "),a("p",[t._v("The index for your corpus can get very large. One way to reduce the size is to disable the forward index for some annotations.")]),t._v(" "),a("p",[t._v('By default, all annotations get a forward index. The forward index is the complement to Lucene\'s reverse index, and can\nquickly answer the question "what value appears in position X of document Y?". This functionality is used to generate\nsnippets (such as for keyword-in-context (KWIC) views), to sort and group based on context words (such as sorting on the word left of the hit) and will in the future be used to speed up certain query types.')]),t._v(" "),a("p",[t._v('However, forward indices take up a lot of disk space and can take up a lot of memory, and they are not always needed for every\nannotation. You should probably have a forward index for at least the word annotation, and for any annotation you\'d like to sort/group on or that you use heavily in searching, or that you\'d like to display in KWIC views. But if you add an annotation that is only used in certain special cases, you can decide to disable the forward index for that annotation. You can do this by adding a setting named "forwardIndex" with the value "false" to the annotation config:')]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" wordId\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" @id\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forwardIndex")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n")])])]),a("p",[t._v("A note about forward indices and indexing multiple values at a single corpus position: as of right now, the forward index will only store the first value indexed at any position. This is the value used for grouping and sorting on this annotation. In the future we may add the ability to store multiple values for a token position in the forward index, although it is likely that the first value will always be the one used for sorting and grouping.")]),t._v(" "),a("p",[t._v("Note that if you want KWICs or snippets that include annotations without a forward index (as well the rest of the original XML), you can switch to using the original XML to generate KWICs and snippets, at the cost of speed. To do this, pass "),a("code",[t._v("usecontent=orig")]),t._v(" to BlackLab Server, or call "),a("code",[t._v("Hits.settings().setConcordanceType(ConcordanceType.CONTENT_STORE)")])]),t._v(" "),a("h3",{attrs:{id:"full-example-of-a-configuration-file"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#full-example-of-a-configuration-file"}},[t._v("#")]),t._v(" Full example of a configuration file")]),t._v(" "),a("p",[t._v("Here's a more-or-less complete overview of what settings can occur in an input format configuration file, with explanatory comments.")]),t._v(" "),a("p",[t._v("Input format configuration files should be named "),a("code",[t._v("<formatIdentifier>.blf.yaml")]),t._v(" or "),a("code",[t._v(".blf.json")]),t._v(" (depending on the format chosen). By default, BlackLab looks in "),a("code",[t._v("$BLACKLAB_CONFIG_DIR/formats/")]),t._v(" (if the environment variable is defined), "),a("code",[t._v("$HOME/.blacklab/formats/")]),t._v(" and "),a("code",[t._v("/etc/blacklab/formats/")]),t._v(". IndexTool searches a few more directories, including the current directory and the parent of the input and index directories.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## For displaying in user interface (optional, recommended)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" OpenSonar FoLiA content format\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## For describing input format in user interface (optional, recommended)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" The file format used by OpenSonar for document contents.\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## What type of input files does this handle? (content, metadata?)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (optional; not used by BlackLab; could be used in user interface)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" content\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## What XML processor to use")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (optional; current default is VTD, but Saxon is recommended because it supports ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  XPath 3.1 and is faster. Future format file versions will probably default to Saxon)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (omit this setting when parsing CSV/TSV or some other file type)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("processor")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" saxon\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## Each file type may have options associated with it (for now, only "tabular" does)')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## We've shown the options for tabular he're but commented them out as we're describing")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## an xml format here.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##fileTypeOptions:")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  type: tsv         # type of tabular format (tsv or csv)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  delimiter: "\\t"   # delimiter, if different from default (determined by "type", tab or comma)')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  quote: "\\""       # quote character, if different from default (double quote)')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  inlineTags: false # are there inline tags in the file like in the Sketch Engine WPL format?")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  glueTags: false   # are there glue tags in the file like in the Sketch Engine WPL format?")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## What namespaces do we use in our XPaths?")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (if omitted: ignore namespaces)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namespaces")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//ilk.uvt.nl/folia    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# ('' -> default namespace)")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## What element starts a new document?")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (the only absolute XPath; the rest is relative)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //FoLiA\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Should documents be stores in the content store?")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## This defaults to true, but you can turn it off if you don't need this.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Annotated, CQL-searchable fields.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## We usually have just one, named "contents".')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# Configuration for the "contents" field')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to display the field in the interface (optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Contents\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to describe the field in the interface (optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Contents of the documents.\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What element (relative to document) contains this field's contents?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (if omitted, entire document is used)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What are our word tags? (relative to container)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If specified, a mapping from this id to token position will be saved, so we ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# can refer back to it for standoff annotations later. (relative to wordPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenIdPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@xml:id"')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What annotation can each word have? How do we index them?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# (annotations are also called "(word) properties" in BlackLab)')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (valuePaths relative to word path)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation is the main annotation")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Words in the text\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" The word forms occurring in the document text.\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" t\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# sensitive|s|insensitive|i|sensitive_insensitive|si|all")]),t._v("\n                                          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# (please explicitly declare this for at least "word" and ')]),t._v("\n                                          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('#  "lemma"; all other annotations will default to insensitive)')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("uiType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (optional) hint for use interface")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forwardIndex")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("                  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# should this annotation get a forward index [true]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma/@class\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# An annotation can have subannotations. This may be useful for e.g.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# part-of-speech features.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("basePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# subsequent XPaths are relative to this")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@class"')]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to basePath)")]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Subannotations")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("subannotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# A single subannotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" head\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@head"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to basePath)")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Multiple subannotations defined at once:")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# visits all elements matched by forEachPath and")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# indexes subannotations based on namePath and valuePath ")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# for each. Note that all subannotations MUST be declared")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# here as well, they just don't need a valuePath. If you")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# don't declare a subannotation, it will generate errors.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forEachPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"feat"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to basePath)")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@subset"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to forEachPath)")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@class"')]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to forEachPath)")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Standoff annotations are annotations that are defined separately from the word")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# elements, elsewhere in the same document. To use standoff annotations, you must")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# define a tokenIdPath (see above). This will make sure you can refer back")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# to token positions so BlackLab knows at what position to index a standoff annotation.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("standoffAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" //timesegment               "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Element containing the values to index")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tokenRefPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" wref/@id  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What token position(s) to index these values at")]),t._v("\n                                        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (these refer back to the tokenIdPath values)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("                      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Annotation(s) to index there")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" begintime\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ../@begintime        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# relative to path")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" endtime\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ../@endtime\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# XML tags within the content we'd like to index")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Any attributes are indexed automatically include/excludeAttributes is used.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (paths relative to container)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//s\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("excludeAttributes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"xml:id"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Skip unique ids (slower, bigger index)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//p\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("includeAttributes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"type"')]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# Only index the "type" attribute')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//ne\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayAs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" named"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("entity    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# what CSS class to use (when using autogenerated XSLT)    ")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (optional)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Analyzer to use for metadata fields if not overridden")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (default|standard|whitespace|your own analyzer)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadataDefaultAnalyzer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" default\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Embedded metadata")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('## (NOTE: shown here is a simple configuration with a single "metadata block";')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('##  however, the value for the "metadata" key may also be a list of such blocks.')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  this can be useful if your document contains multiple areas with metadata ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("##  you want to index)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Where the embedded metadata is found (relative to documentPath)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("@type='native'"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How each of the metadata fields can be found (relative to containerPath)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Single metadata field")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to containerPath)")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Multiple metadata fields defined at once:")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# visits all elements matched by forEachPath and")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# adds a metadata entry based on namePath and ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# valuePath for each)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("forEachPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" meta    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to containerPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"@id"')]),t._v("      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to forEachPath)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .         "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (relative to forEachPath)")]),t._v("\n    \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## (optional)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## It is possible to specify a mapping to change the name of")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## metadata fields. This can be useful if you capture a lot of")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## metadata fields using forEachPath and want control over how they")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## are indexed.    ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("indexFieldAs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("lessThanIdealName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" muchBetterName\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("alsoNotAGreatName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" butThisIsExcellent\n\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Linked metadata (or other linked document)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkedDocuments")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# What does the linked document represent?")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (this is used internally to determine the name of the field to store content store id in)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Should we store the linked document?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Values we need to locate the linked document")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (matching values will be substituted for $1-$9 below - the first linkValue is $1, etc.)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valueField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" fromInputFile       "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# fetch the "fromInputFile" field from the Lucene doc')]),t._v("\n\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# We process the raw value:")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# - we replace backslashes with forward slashes")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# - we keep only the last two path parts (e.g. /a/b/c/d --\x3e c/d)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# - we replace .folia. with .cmdi.")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (processing steps like these can also be used with metadata fields and annotations!")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#  see elsewhere for a list of available processing steps)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize slashes")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\\\\\"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Keep only the last two path parts (which indicate location inside metadata zip file)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^.*/([^/]+/[^/]+)/?$"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$1"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\.folia\\\\."')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".cmdi."')]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to fetch the linked input file containing the linked document")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (file or http(s) reference)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /molechaser/data/opensonar/metadata/SONAR500NEW.zip\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If the linked input file is an archive, this is the path inside the archive where the file can be found")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("pathInsideArchive")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" SONAR500/DATA/$1\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# XPath to the (single) linked document to process.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If omitted, the entire file is processed, and must contain only one document.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#documentPath: /CMD/Components/SoNaRcorpus/Text[@ComponentId = $2]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Format identifier of the linked input file")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFormat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" OpenSonarCmdi\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Configuration to be copied into indexmetadata.yaml when a new index is created")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## from this format. These settings do not influence indexing but are for ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## BlackLab Server and search user interfaces. All settings are optional.")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("corpusConfig")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Display name for the corpus")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("displayName")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" My Amazing Corpus\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Short description for the corpus ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("description")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Quite an amazing corpus"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" if I do say so myself.\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Is the user allowed to view whole documents in the search interface?")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (used by BLS to either allow or disallow fetching full document content)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (defaults to false because this is not allowed for some datasets)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contentViewable")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# Text direction of this corpus (e.g. "LTR", "left-to-right", "RTL", etc.).')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (default: LTR)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("textDirection")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" LTR\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# You can divide annotations for an annotated field into groups, which can")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# be useful if you want to display them in a tabbed interface.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Our corpus frontend uses this setting.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotationGroups")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Basic\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" word\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Advanced\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" pos\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("addRemainingAnnotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# You can divide your metadata fields into groups, which can")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# be useful if you want to display them in a tabbed interface.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Our corpus frontend uses this setting.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadataFieldGroups")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Tab1\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" Field1\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" Field2\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" Tab2\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" Field3\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" Field4\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" OtherFields\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("addRemainingFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# BLS will add any field not yet in ")]),t._v("\n                                "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# any group to this group   ")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (optional, but pidField is highly recommended)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# You can specify metadata fields that have special significance here.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# pidField is important for use with BLS because it guarantees that URLs")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# won't change even if you re-index. The other fields can be nice for")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# displaying document information but are not essential.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("specialFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("pidField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" id         "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique document identifier. Used by BLS for persistent URLs")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("titleField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" title    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# may be used by user interface to display document info")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("authorField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# may be used by user interface to display document info")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dateField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pubDate   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# may be used by user interface to display document info")]),t._v("\n")])])]),a("h2",{attrs:{id:"advanced"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#advanced"}},[t._v("#")]),t._v(" Advanced")]),t._v(" "),a("h3",{attrs:{id:"unicode-normalization"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#unicode-normalization"}},[t._v("#")]),t._v(" Unicode normalization")]),t._v(" "),a("p",[t._v("Unicode normalization refers to the process of converting different ways of encoding the same character to a single, canonical form. For example, the character "),a("code",[t._v("é")]),t._v(" can be encoded as a single character "),a("code",[t._v("é")]),t._v(" (U+00E9), or as a combination of "),a("code",[t._v("e")]),t._v(" (U+0065) and "),a("code",[t._v("´")]),t._v(" (U+00B4).")]),t._v(" "),a("p",[t._v("BlackLab's builtin indexers should automatically normalize to NFC (Normalization Form Canonical Composition). This should prevent any issues when sorting or grouping.")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://en.wikipedia.org/wiki/Unicode_equivalence",target:"_blank",rel:"noopener noreferrer"}},[t._v("More about Unicode equivalence and normal forms"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"automatic-xslt-generation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#automatic-xslt-generation"}},[t._v("#")]),t._v(" Automatic XSLT generation")]),t._v(" "),a("p",[t._v("If you're creating your own corpora by uploading data to corpus-frontend, you want to be able to view your documents as well, without having to write an XSLT yourself. BlackLab Server can generate a default XSLT from your format config file. However, because BlackLab is a bit more lenient with namespaces than the XSLT processor that generates the document view, the generated XSLT will only work correctly if you take care to define your namespaces correctly in your format config file.")]),t._v(" "),a("p",[t._v("IMPORTANT: generating the XSLT might not work correctly if your XML namespaces change throughout the document, e.g. if you declare local namespaces on elements, instead of")]),t._v(" "),a("p",[t._v('Namespaces can be declared in the top-level "namespaces" block, which is simply a map of namespace prefix (e.g. "tei") to the namespace URI (e.g. '),a("code",[t._v("http://www.tei-c.org/ns/1.0")]),t._v("). So for example, if your documents declare namespaces as follows:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("doc")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("xmlns:")]),t._v("my-ns")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("http://example.com/my-ns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("xmlns")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("http://example.com/other-ns"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n...\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("doc")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("Then your format config file should contain this namespaces section:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("namespaces")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//example.com/other"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("ns    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The default namespace")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("my-ns")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//example.com/my"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("ns\n")])])]),a("p",[t._v("If you forget to declare some or all of these namespaces, the document might index correctly, but the generated XSLT won't work and will likely show a message saying that no words have been found in the document. Updating your format config file should fix this; re-indexing shouldn't be necessary, as the XSLT is generated directly from the config file, not the index.")]),t._v(" "),a("h3",{attrs:{id:"multiple-values-at-one-position"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#multiple-values-at-one-position"}},[t._v("#")]),t._v(" Multiple values at one position")]),t._v(" "),a("p",[t._v("Standoff annotations (see below) provide a way to index additional values at the same token position. But it is also possible to just index several values for any regular annotation, such as multiple lemmatizations or multiple possible part of speech tags.")]),t._v(" "),a("p",[t._v("If your data looks like this:")]),t._v(" "),a("div",{staticClass:"language-xml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-xml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token prolog"}},[t._v('<?xml version="1.0" ?>')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("Helo"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("hello"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")]),t._v("halo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("'")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("wold"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("t")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("world"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("lemma")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),a("span",{pre:!0,attrs:{class:"token attr-value"}},[a("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("would"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("/>")])]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("w")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("document")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token tag"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("root")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),a("p",[t._v("You can index all the values for lemma at the same token position like this:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("wordPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .//w\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" t\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("multipleValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n")])])]),a("p",[t._v("If you don't specify multipleValues, only the first value will be used. The reason you explicitly have to specify it is that this is relatively rare and could slow down the indexing process if automatically applied to all annotations.")]),t._v(" "),a("p",[t._v("When indexing multiple values at a single position, it is possible to match the same value multiple times, for example when creating an annotation that combines word and lemma (useful for simple search). This would lead to duplicate matches. If this is not what you want, you can set "),a("code",[t._v("allowDuplicateValues")]),t._v(" to false."),a("br"),t._v("\nNote that duplicates are checked case-insensitive. The value in the index will keep its capitalization however.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[t._v("    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word_and_lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word or lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("multipleValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("allowDuplicateValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v(" \n")])])]),a("p",[t._v("Multiple value annotations also work for tabular formats like csv, tsv or sketch-wpl. You can specify a regular expression to use for splitting a column value into multiple values. The default is a semicolon "),a("code",[t._v(";")]),t._v(". You can change it as follows:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[t._v("    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tabular\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileTypeOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("multipleValuesSeparator")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/"')]),t._v("\n")])])]),a("h3",{attrs:{id:"indexing-raw-xml"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-raw-xml"}},[t._v("#")]),t._v(" Indexing raw XML")]),t._v(" "),a("p",[t._v("An annotation can optionally capture the raw xml content:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[t._v("    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word_xml\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("captureXml")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n")])])]),a("h3",{attrs:{id:"indexing-csv-tsv-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-csv-tsv-files"}},[t._v("#")]),t._v(" Indexing CSV/TSV files")]),t._v(" "),a("p",[t._v("BlackLab works best with XML files, because they can contain any kind of (sub)annotations, (embedded or linked) metadata, inline tags, and so on. However, if your data is in a non-XML type like CSV, TSV or plain text, and you'd rather not convert it, you can still index it.")]),t._v(" "),a("p",[t._v('For CSV/TSV files, indexing them directly can be done by defining a tabular input format. These are "word-per-line" (WPL) formats, meaning that each line will be interpreted as a single token. Annotations simply specify the column number (or column name, if your input files have them).')]),t._v(" "),a("p",[t._v("(Technical note: BlackLab uses "),a("a",{attrs:{href:"https://commons.apache.org/proper/commons-csv/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Apache commons-csv"),a("OutboundLink")],1),t._v(" to parse tabular files. Not all settings are exposed at the moment. If you find yourself needing access to a setting that isn't exposed via de configuration file yet, please let us know)")]),t._v(" "),a("p",[t._v("Here's a simple example configuration, "),a("code",[t._v("my-tsv.blf.yaml")]),t._v(", that will parse tab-delimited files produced by the "),a("a",{attrs:{href:"https://languagemachines.github.io/frog/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Frog"),a("OutboundLink")],1),t._v(" tool:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tabular\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("## Options for tabular format")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileTypeOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# TSV (tab-separated values) or CSV (comma-separated values, like Excel)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Does the file have column names in the first line? [default: false]")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("columnNames")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v("\n  \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The delimiter character to use between column values")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# [default: comma (",") for CSV, tab ("\\t") for TSV]')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("delimiter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\t"')]),t._v("\n  \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# The quote character used around column values (where necessary)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [default: disable quoting column values]")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("quote")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\""')]),t._v("\n  \n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (1-based) column number or column name (if file has them) ")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),t._v("\n")])])]),a("p",[t._v("(Note that the BlackLab JAR includes a default "),a("code",[t._v("tsv.blf.yaml")]),t._v(" that is a bit different: it assumes a file containing column names. The column names are word, lemma and pos)")]),t._v(" "),a("p",[t._v('The Sketch Engine takes a tab-delimited WPL input format that document tags, inline tags and "glue tags" (which indicate that there should be no space between two tokens). Here\'s a short example:')]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('<doc id="1" title="Test document" author="Jan Niestadt"> \n<s> \nThis    PRO     this\nis      VRB     be\na       ART     a\ntest    NOU     test\n<g/>\n.       SENT    .\n</s>\n</doc>  \n')])])]),a("p",[t._v("Here's a configuration to index this format ("),a("code",[t._v("sketch-wpl.blf.yaml")]),t._v(", already included in the BlackLab JAR):")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tabular\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileTypeOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n  \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# allows inline tags such as in Sketch WPL format")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# all inline tags encountered will be indexed")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("  \n                    \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# interprets <g/> to be a glue tag such as in Sketch WPL format")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("glueTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("\n  \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# If the file includes "inline tags" like <p></p> and <s></s>,')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (like for example the Sketch Engine WPL format does)")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# is it allowed to have separated characters after such a tag?")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [default: false]")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("allowSeparatorsAfterInlineTags")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("false")]),t._v(" \n  \n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("documentPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" doc   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# looks for document elements such as in Sketch WPL format")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (attributes are automatically indexed as metadata)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# First annotation becomes the main annotation")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" lemma\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pos\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n")])])]),a("p",[t._v("If one of your columns contains multiple values, for example multiple alternative lemmatizations, set the "),a("code",[t._v("multipleValues")]),t._v(" option for that annotation to true and specify a regular expression to use for splitting a column value into multiple values in the "),a("code",[t._v("fileTypeOptions")]),t._v(". The default is a semicolon "),a("code",[t._v(";")]),t._v(". See also "),a("RouterLink",{attrs:{to:"/guide/how-to-configure-indexing.html#multiple-values-at-one-position"}},[t._v("here")]),t._v(".")],1),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tabular\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileTypeOptions")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" tsv\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("multipleValuesSeparator")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/"')]),t._v("\n")])])]),a("p",[t._v("If you want to index metadata from another file along with each document, you have to use "),a("code",[t._v("valueField")]),t._v(" in the "),a("code",[t._v("linkValues")]),t._v(" section (see "),a("a",{attrs:{href:"#metadata-external"}},[t._v("below")]),t._v("). In the SketchWPL case, in addition to "),a("code",[t._v("fromInputFile")]),t._v(" you can also use any document element attributes, because those are added as metadata fields automatically. So if the document element has an "),a("code",[t._v("id")]),t._v(" attribute, you could use that as a "),a("code",[t._v("linkValue")]),t._v(" to locate the metadata file.")]),t._v(" "),a("h3",{attrs:{id:"indexing-plain-text-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-plain-text-files"}},[t._v("#")]),t._v(" Indexing plain text files")]),t._v(" "),a("p",[t._v("Plain text files don't allow you to use a lot of BlackLab's features and hence don't require a lot of configuration either. If you need specific indexing features for non-tabular, non-XML file formats, please let us know and we will consider adding them. For now, here's how to configure a plain text input format ("),a("code",[t._v("txt.blf.yaml")]),t._v(", included in the BlackLab JAR):")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fileType")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" text\n\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotatedFields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("contents")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("annotations")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" word\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" .\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("sensitivity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" sensitive_insensitive\n")])])]),a("p",[t._v('Note that a plain text format may only have a single annotated field. You cannot specify containerPath or wordPath. For each annotation you define, valuePath must be "." ("the current word"), but you can specify different processing steps for different annotations if you want.')]),t._v(" "),a("p",[t._v("There is one way to index metadata information along with plain text files, which is to look up the metadata based on the input file. The example below uses processing steps; see the relevant section below, and see the section on linking to external files for more information on that subject.")]),t._v(" "),a("p",[t._v("To index metadata information based on the input file path, use a section such as this one:")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkedDocuments")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("store")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean important"}},[t._v("true")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Should we store the linked document?")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Values we need for locating the linked document")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (matching values will be substituted for $1-$9 below)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("linkValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valueField")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" fromInputFile       "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# fetch the "fromInputFile" field from the Lucene doc')]),t._v("\n                                      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (this is the original path to the file that was indexed)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize slashes")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\\\\\"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"/"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Keep only the last two path parts (which indicate location inside metadata zip file)")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"^.*/([^/]+/[^/]+)/?$"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"$1"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\.txt$"')]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".cmdi"')]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#- valueField: id                 # plain text has no other fields, but TSV with document elements")]),t._v("\n                                      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# could, and those fields could also be used (see documentPath ")]),t._v("\n                                      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# below)")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# How to fetch the linked input file containing the linked document.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# File or http(s) reference. May contain $x (x = 1-9), which will be replaced ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("//server.example.com/metadata.zip\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If the linked input file is an archive (zip is recommended), this is the path ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# inside the archive where the file can be found. May contain $x (x = 1-9), which ")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("pathInsideArchive")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" some/dir/$1\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Format of the linked input file")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("inputFormat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" cmdi\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (Optional)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# XPath to the (single) linked document to process.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If omitted, the entire file is processed, and must contain only one document.")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# May contain $x (x = 1-9), which will be replaced with (processed) linkValue")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#documentPath: /root/metadata[@docId = $2]")]),t._v("\n")])])]),a("h3",{attrs:{id:"indexing-other-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#indexing-other-files"}},[t._v("#")]),t._v(" Indexing other files")]),t._v(" "),a("p",[t._v("For some types of files it is possible to automatically convert them to another file type that can be indexed."),a("br"),t._v("\nSupport for this feature works through plugins and is still experimental.")]),t._v(" "),a("p",[t._v("Add the following lines to your configuration file to convert your files before indexing them according to the rest of the configuration.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("convertPlugin")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" OpenConvert\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("tagPlugin")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" DutchTagger\n")])])]),a("p",[t._v("This setup will convert "),a("code",[t._v("doc, docx, txt, epub, html, alto, rtf and odt")]),t._v(" into "),a("code",[t._v("tei")]),t._v(".")]),t._v(" "),a("p",[t._v("This will however not work until you provide the right .jar and data files to the plugins. Adding the following configuration to "),a("code",[t._v("blacklab.json")]),t._v(" will enable the plugins to do their work.")]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("plugins")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("OpenConvert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("jarPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /path/to/OpenConvert"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("0.2.0.jar\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("DutchTagger")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("jarPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /path/to//DutchTagger"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v("0.2.0.jar\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("vectorFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /path/to/duthtagger/data/vectors.bin\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("modelFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /path/to/dutchtagger/model\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("lexiconFile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" /path/to/dutchtagger/lexicon.tab\n")])])]),a("p",[t._v("Currently the files and exact version of OpenConvert are not publically available, but look at the "),a("RouterLink",{attrs:{to:"/development/customization/plugins.html"}},[t._v("plugins")]),t._v(" page for more information on how write your own plugin.")],1),t._v(" "),a("h3",{attrs:{id:"processing-values"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#processing-values"}},[t._v("#")]),t._v(" Processing values")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("NOTE:")]),t._v(" when using Saxon as your XML processor, you can usually achieve the same results using XPath expressions, and this is the recommended approach. See "),a("RouterLink",{attrs:{to:"/guide/xpath-examples.html"}},[t._v("XPath examples")]),t._v(" for some examples.")],1)]),t._v(" "),a("p",[t._v("It is often useful to do some simple processing on a value just before it's added to the index. This could be a simple search and replace, or combining two fields into one for easier searching, etc. Or you might want to map a whole collection of values to different values. Both are possible.")]),t._v(" "),a("p",[t._v('To perform simple value mapping on a metadata field, add the "mapValues" key to its config, like this:')]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" speciesGroup\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" species\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Map (translate) values (key will be translated to corresponding value)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# In this example: translate species to the group they belong to")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("mapValues")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("dog")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mammals\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("cat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" mammals\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("shark")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" fish\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("herring")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" fish\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# etc.")]),t._v("\n")])])]),a("p",[t._v('To perform string processing on (standoff) (sub)annotations, metadata values, and linkValues (in the linked document section, see "Linking to external (metadata) files").')]),t._v(" "),a("p",[t._v('For example, to process a metadata field value, simply add a "process" key with a list of actions to perform, like so:')]),t._v(" "),a("div",{staticClass:"language-yaml extra-class"},[a("pre",{pre:!0,attrs:{class:"language-yaml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("metadata")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("containerPath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" metadata\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("fields")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("valuePath")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" author\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Do some processing on the contents of the author element before indexing")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# If empty, set a default value")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (note that this could also be achieved using unknownCondition/unknownValue)")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" default\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("value")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"(unknown)"')]),t._v("\n                          \n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize spaces")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("action")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" replace\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("find")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\s\\\\s+"')]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[t._v("replace")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),t._v("\n")])])]),a("p",[t._v("These are all the available generic processing steps:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("replace(find, replace)")]),t._v(": do a regex search for 'find' and replace each match with 'replace'. Group references may be used. An optional parameter "),a("code",[t._v("keep")]),t._v(" can be set to "),a("code",[t._v("all")]),t._v(" to keep both  the original strings and the results after applying the replace operation (annotation must have "),a("code",[t._v("multipleValues: true")]),t._v(" for this to work).")]),t._v(" "),a("li",[a("code",[t._v("default(value)")]),t._v(" or "),a("code",[t._v("default(field)")]),t._v(": if the field is empty, set its value to either the specified value or the value of the specified field. If you refer to a field, make sure it is defined before this field (fields are processed in order).")]),t._v(" "),a("li",[a("code",[t._v("append(value)")]),t._v(" or "),a("code",[t._v("append(field)")]),t._v(": append the specified value or the value of the specified field, using a space as the separator character. You may also specify a different "),a("code",[t._v("separator")]),t._v(" is you wish, including the empty string ("),a("code",[t._v('""')]),t._v(").")]),t._v(" "),a("li",[a("code",[t._v("split(separator, keep)")]),t._v(": split the field's value on the given separator and keep only the part indicated by keep (a 1-based integer). If "),a("code",[t._v("keep")]),t._v(" is omitted, keep the first part. If "),a("code",[t._v("separator")]),t._v(" is omitted, use "),a("code",[t._v(";")]),t._v("."),a("br"),t._v("\nNote that the separator is a regex, and to split on special characters, those should be escaped by using a double backslash ("),a("code",[t._v("\\\\")]),t._v(")."),a("br"),t._v(" "),a("code",[t._v("Keep")]),t._v(" also allows two special values: "),a("code",[t._v("all")]),t._v(" to keep all splits (instead of one the one at an index), and "),a("code",[t._v("both")]),t._v(" to keep both the unsplit value as well as all the split parts. For "),a("code",[t._v("both")]),t._v(" to work, the annotation should also specify "),a("code",[t._v("multipleValues")]),t._v(" to be true.")]),t._v(" "),a("li",[a("code",[t._v("strip(chars)")]),t._v(": strip specified chars from beginning and end. If "),a("code",[t._v("chars")]),t._v(" is omitted, use space.")])]),t._v(" "),a("p",[t._v("These processing steps are more specific to certain data formats:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("parsePos(posExpr, fieldName)")]),t._v(": parse common part of speech expressions of the form "),a("code",[t._v("A(b=c,d=e)")]),t._v(" where A is the main part of speech (e.g. 'N' for noun), and b=c is a part of speech feature such as number=plural, etc. If you don't specify field (or specify an underscore _ for field), the main part of speech is extracted. If you specify a feature name (e.g. \"number\"), that feature is extracted.")]),t._v(" "),a("li",[a("code",[t._v("chatFormatAgeToMonths(chatFormatAge)")]),t._v(": convert age as reported in CHAT format to number of months")]),t._v(" "),a("li",[a("code",[t._v("concatDate")]),t._v(": concatenate 3 separate date fields into one, substituting unknown months and days with the first or last possible value. The output format is YYYYMMDD. Numbers are padded with leading zeroes.\nRequires 4 arguments:\n"),a("code",[t._v("yearField")]),t._v(": the metadata field containing the numeric year\n"),a("code",[t._v("monthField")]),t._v(': the metadata field containing the numeric month (so "12" instead of "december" or "dec")\n'),a("code",[t._v("dayField")]),t._v(": the metadata field containing the numeric day\n"),a("code",[t._v("autofill")]),t._v(": "),a("code",[t._v("start")]),t._v(" to autofill missing month and day to the first possible value (01), or "),a("code",[t._v("end")]),t._v(" to autofill the last possible value (12 for months, last day of the month in that year for days - takes in to account leap years).\nThis step requires that at least the year is known. If the year is not known, no output is generated.")])]),t._v(" "),a("p",[t._v("If you would like a new processing step to be added, please let us know.")]),t._v(" "),a("p",[a("strong",[t._v("NOTE:")]),t._v(" value mapping using "),a("code",[t._v("mapValues")]),t._v(" is applied "),a("em",[t._v("after")]),t._v(" any processing steps.")]),t._v(" "),a("h3",{attrs:{id:"extending-formats-deprecated"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#extending-formats-deprecated"}},[t._v("#")]),t._v(" Extending formats (deprecated)")]),t._v(" "),a("blockquote",[a("p",[a("strong",[t._v("NOTE: THIS FUNCTIONALITY IS DEPRECATED")]),t._v(" "),a("br"),t._v("\nDon't rely on this feature as it will be removed in a future version. Instead, simply copy the format file and make any changes you need.")])]),t._v(" "),a("p",[t._v('It is possible to extend an existing format. This is done by specifying the "baseFormat" setting at the top-level. You should set it to the name of the format you wish to extend.')]),t._v(" "),a("p",[t._v("It matters where baseFormat is placed, as it effectively copies values from the specified format when it is encountered. It's usually best to specify baseFormat somewhere at the top of the file. You can put it after 'name' and 'description' if you wish, as those settings are not copied.")]),t._v(" "),a("p",[t._v("To be precise, setting baseFormat does the following:")]),t._v(" "),a("ul",[a("li",[t._v("copy type, fileType, documentPath, store, metadataDefaultAnalyzer")]),t._v(" "),a("li",[t._v("copy the corpusConfig settings")]),t._v(" "),a("li",[t._v("add all fileTypeOptions")]),t._v(" "),a("li",[t._v("add all namespace declarations")]),t._v(" "),a("li",[t._v("add all indexFieldAs entries")]),t._v(" "),a("li",[t._v("add all annotatedFields entries")]),t._v(" "),a("li",[t._v("add all metadata entries")]),t._v(" "),a("li",[t._v("add all linkedDocument entries")])]),t._v(" "),a("p",[t._v("In other words: setting a base format allows you to add or change file type options, namespace declarations, indexFieldAs entries, annotated fields or linked documents. You can also add (embedded) metadata sections.")]),t._v(" "),a("p",[t._v('Note that most blocks are not "merged": if you want to change annotated field settings, you will have to redefine the entire annoted field in the "derived" configuration file; you can\'t just specify the setting you wish to override for that field. It is also not possible to make changes to existing metadata sections.')])])}),[],!1,null,null,null);a.default=e.exports}}]);